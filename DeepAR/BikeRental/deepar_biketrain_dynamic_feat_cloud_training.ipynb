{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_categories = False\n",
    "# Set a good base job name when building different models\n",
    "# It will help in identifying trained models and endpoints\n",
    "base_job_name = 'deepar-biketrain-with-dynamic-feat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'chandra-ml-sagemaker'\n",
    "prefix = 'deepar/bikerental'\n",
    "\n",
    "# This structure allows multiple training and test files for model development and testing\n",
    "s3_data_path = \"{}/{}/data_dynamic\".format(bucket, prefix)\n",
    "s3_output_path = \"{}/{}/output\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chandra-ml-sagemaker/deepar/bikerental/data_dynamic',\n",
       " 'chandra-ml-sagemaker/deepar/bikerental/output')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_data_path,s3_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name is referred as key name in S3\n",
    "# Files stored in S3 are automatically replicated across\n",
    "# three different availability zones in the region where the bucket was created.\n",
    "# http://boto3.readthedocs.io/en/latest/guide/s3.html\n",
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename,'rb') as f: # Read in binary mode\n",
    "        return boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload one or more training files and test files to S3\n",
    "write_to_s3('train_dynamic_feat.json',bucket,'deepar/bikerental/data_dynamic/train/train_dynamic_feat.json')\n",
    "write_to_s3('test_dynamic_feat.json',bucket,'deepar/bikerental/data_dynamic/test/test_dynamic_feat.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We no longer have to maintain a mapping of container images by region\n",
    "# Simply use the convenience method provided by sagemaker\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "image_name = get_image_uri(boto3.Session().region_name, 'forecasting-deepar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'522234722520.dkr.ecr.us-east-1.amazonaws.com/forecasting-deepar:1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq='H' # Timeseries consists Hourly Data and we need to predict hourly rental count\n",
    "\n",
    "# how far in the future predictions can be made\n",
    "# 12 days worth of hourly forecast \n",
    "prediction_length = 288 \n",
    "\n",
    "# aws recommends setting context same as prediction length as a starting point. \n",
    "# This controls how far in the past the network can see\n",
    "context_length = 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Free Tier (if you are still under free-tier)\n",
    "# At this time, m4.xlarge is offered as part of 2 months free tier\n",
    "# https://aws.amazon.com/sagemaker/pricing/\n",
    "# If you are outside of free-tier, you can also use ml.m5.xlarge  (newer generation instance)\n",
    "# In this example, I am using ml.m5.xlarge for training\n",
    "\n",
    "# Dynamic Feat - Using a large instance ml.c5.4xlarge = 16 CPU, 32 GB\n",
    "# 'ml.c4.xlarge' -> 'ml.c5.4xlarge'. out of memory error with c4.xlarge\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c5.4xlarge',\n",
    "    base_job_name=base_job_name,\n",
    "    output_path=\"s3://\" + s3_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('H', 288, 288)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq, context_length, prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_hyperparameters.html\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"cardinality\" : \"auto\" if with_categories else ''\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_freq': 'H',\n",
       " 'epochs': '400',\n",
       " 'early_stopping_patience': '40',\n",
       " 'mini_batch_size': '64',\n",
       " 'learning_rate': '5E-4',\n",
       " 'context_length': '288',\n",
       " 'prediction_length': '288',\n",
       " 'cardinality': ''}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we are simply referring to train path and test path\n",
    "# You can have multiple files in each path\n",
    "# SageMaker will use all the files\n",
    "data_channels = {\n",
    "    \"train\": \"s3://{}/train/\".format(s3_data_path),\n",
    "    \"test\": \"s3://{}/test/\".format(s3_data_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 's3://chandra-ml-sagemaker/deepar/bikerental/data_dynamic/train/',\n",
       " 'test': 's3://chandra-ml-sagemaker/deepar/bikerental/data_dynamic/test/'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-23 23:53:26 Starting - Starting the training job...\n",
      "2020-04-23 23:53:27 Starting - Launching requested ML instances......\n",
      "2020-04-23 23:54:30 Starting - Preparing the instances for training...\n",
      "2020-04-23 23:55:18 Downloading - Downloading input data...\n",
      "2020-04-23 23:55:53 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'288', u'epochs': u'400', u'time_freq': u'H', u'context_length': u'288', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'288', u'time_freq': u'H', u'context_length': u'288', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train_dynamic_feat.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train_dynamic_feat.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=8 from dataset.\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] Integer time series\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] number of time series: 3\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] number of observations: 50904\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] mean target length: 16968\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] min/mean/max target: 0.0/79.5729608675/977.0\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] mean abs(target): 79.5729608675\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] contains missing values: yes (37.5%)\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] Small number of time series. Doing 214 passes over dataset with prob 0.996884735202 per epoch.\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] Test set statistics:\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] Integer time series\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] number of time series: 3\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] number of observations: 51768\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] mean target length: 17256\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] min/mean/max target: 0.0/80.5700819039/977.0\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] mean abs(target): 80.5700819039\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:54 INFO 139658144298816] contains missing values: yes (36.9%)\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:55 INFO 139658144298816] nvidia-smi took: 0.0251259803772 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:55 INFO 139658144298816] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:55:55 INFO 139658144298816] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 20658.300161361694, \"sum\": 20658.300161361694, \"min\": 20658.300161361694}}, \"EndTime\": 1587686175.670686, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686155.011612}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:15 INFO 139658144298816] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 23470.563888549805, \"sum\": 23470.563888549805, \"min\": 23470.563888549805}}, \"EndTime\": 1587686178.482294, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686175.671141}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:28 INFO 139658144298816] Epoch[0] Batch[0] avg_epoch_loss=4.569305\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.56930494308\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:32 INFO 139658144298816] Epoch[0] Batch[5] avg_epoch_loss=4.391783\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=4.39178347588\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:32 INFO 139658144298816] Epoch[0] Batch [5]#011Speed: 89.81 samples/sec#011loss=4.391783\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:35 INFO 139658144298816] Epoch[0] Batch[10] avg_epoch_loss=4.154434\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:35 INFO 139658144298816] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.86961398125\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:35 INFO 139658144298816] Epoch[0] Batch [10]#011Speed: 90.05 samples/sec#011loss=3.869614\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:35 INFO 139658144298816] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 17268.02897453308, \"sum\": 17268.02897453308, \"min\": 17268.02897453308}}, \"EndTime\": 1587686195.750587, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686178.482461}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:35 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=37.5836742935 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:35 INFO 139658144298816] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:35 INFO 139658144298816] #quality_metric: host=algo-1, epoch=0, train loss <loss>=4.15443370559\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:35 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:35 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_ee9a257f-77cf-459b-930b-e79a2371288f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 205.58714866638184, \"sum\": 205.58714866638184, \"min\": 205.58714866638184}}, \"EndTime\": 1587686195.956613, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686195.750663}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:45 INFO 139658144298816] Epoch[1] Batch[0] avg_epoch_loss=4.059844\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=4.05984401703\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:48 INFO 139658144298816] Epoch[1] Batch[5] avg_epoch_loss=3.937394\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:48 INFO 139658144298816] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.93739382426\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:48 INFO 139658144298816] Epoch[1] Batch [5]#011Speed: 94.07 samples/sec#011loss=3.937394\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:52 INFO 139658144298816] Epoch[1] Batch[10] avg_epoch_loss=3.836967\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.71645379066\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:52 INFO 139658144298816] Epoch[1] Batch [10]#011Speed: 90.18 samples/sec#011loss=3.716454\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:52 INFO 139658144298816] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16344.308137893677, \"sum\": 16344.308137893677, \"min\": 16344.308137893677}}, \"EndTime\": 1587686212.301036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686195.956671}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:52 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.6867256854 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:52 INFO 139658144298816] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.83696653626\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:52 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:56:52 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_12c8f367-da18-4b37-8057-4254d27c44f2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 230.07893562316895, \"sum\": 230.07893562316895, \"min\": 230.07893562316895}}, \"EndTime\": 1587686212.531487, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686212.301096}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:01 INFO 139658144298816] Epoch[2] Batch[0] avg_epoch_loss=3.668146\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.668145895\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:05 INFO 139658144298816] Epoch[2] Batch[5] avg_epoch_loss=3.652150\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.65215043227\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:05 INFO 139658144298816] Epoch[2] Batch [5]#011Speed: 93.68 samples/sec#011loss=3.652150\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/23/2020 23:57:08 INFO 139658144298816] Epoch[2] Batch[10] avg_epoch_loss=3.619649\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.58064804077\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:08 INFO 139658144298816] Epoch[2] Batch [10]#011Speed: 89.99 samples/sec#011loss=3.580648\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:08 INFO 139658144298816] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16290.640115737915, \"sum\": 16290.640115737915, \"min\": 16290.640115737915}}, \"EndTime\": 1587686228.822237, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686212.531545}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:08 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.127719786 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:08 INFO 139658144298816] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.61964934522\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:08 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:09 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_cbdbf24e-d936-4dc9-833c-76683833314e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 183.32791328430176, \"sum\": 183.32791328430176, \"min\": 183.32791328430176}}, \"EndTime\": 1587686229.005897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686228.822285}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:18 INFO 139658144298816] Epoch[3] Batch[0] avg_epoch_loss=3.475542\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=3.47554159164\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:21 INFO 139658144298816] Epoch[3] Batch[5] avg_epoch_loss=3.573399\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=3.5733987093\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:21 INFO 139658144298816] Epoch[3] Batch [5]#011Speed: 92.27 samples/sec#011loss=3.573399\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:24 INFO 139658144298816] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15743.075132369995, \"sum\": 15743.075132369995, \"min\": 15743.075132369995}}, \"EndTime\": 1587686244.749075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686229.005952}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:24 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.8268399087 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:24 INFO 139658144298816] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.52207827568\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:24 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:24 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_302b654a-b3c2-4cbc-a649-cd086d233964-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 184.0651035308838, \"sum\": 184.0651035308838, \"min\": 184.0651035308838}}, \"EndTime\": 1587686244.933535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686244.749126}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:34 INFO 139658144298816] Epoch[4] Batch[0] avg_epoch_loss=3.331584\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=3.33158373833\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:37 INFO 139658144298816] Epoch[4] Batch[5] avg_epoch_loss=3.560120\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=3.56012014548\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:37 INFO 139658144298816] Epoch[4] Batch [5]#011Speed: 92.15 samples/sec#011loss=3.560120\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:41 INFO 139658144298816] Epoch[4] Batch[10] avg_epoch_loss=3.633141\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=3.72076568604\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:41 INFO 139658144298816] Epoch[4] Batch [10]#011Speed: 90.17 samples/sec#011loss=3.720766\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:41 INFO 139658144298816] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16395.72501182556, \"sum\": 16395.72501182556, \"min\": 16395.72501182556}}, \"EndTime\": 1587686261.329375, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686244.933596}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:41 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.1932205207 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:41 INFO 139658144298816] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=4, train loss <loss>=3.63314084573\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:41 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:50 INFO 139658144298816] Epoch[5] Batch[0] avg_epoch_loss=3.488166\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:50 INFO 139658144298816] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=3.48816609383\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:54 INFO 139658144298816] Epoch[5] Batch[5] avg_epoch_loss=3.499109\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=3.49910891056\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:54 INFO 139658144298816] Epoch[5] Batch [5]#011Speed: 92.21 samples/sec#011loss=3.499109\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:57 INFO 139658144298816] Epoch[5] Batch[10] avg_epoch_loss=3.508316\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=3.51936368942\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:57 INFO 139658144298816] Epoch[5] Batch [10]#011Speed: 89.51 samples/sec#011loss=3.519364\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:57 INFO 139658144298816] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16618.233919143677, \"sum\": 16618.233919143677, \"min\": 16618.233919143677}}, \"EndTime\": 1587686277.947958, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686261.329425}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:57 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.617828875 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:57 INFO 139658144298816] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=5, train loss <loss>=3.50831562823\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:57 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:57:58 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_3bb6981a-1061-4f18-9a75-19d2b7851a33-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 182.60693550109863, \"sum\": 182.60693550109863, \"min\": 182.60693550109863}}, \"EndTime\": 1587686278.130934, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686277.948016}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:07 INFO 139658144298816] Epoch[6] Batch[0] avg_epoch_loss=3.462012\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:07 INFO 139658144298816] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=3.4620115757\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:11 INFO 139658144298816] Epoch[6] Batch[5] avg_epoch_loss=3.432168\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:11 INFO 139658144298816] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=3.43216820558\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:11 INFO 139658144298816] Epoch[6] Batch [5]#011Speed: 92.53 samples/sec#011loss=3.432168\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:14 INFO 139658144298816] Epoch[6] Batch[10] avg_epoch_loss=3.334333\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=3.21692991257\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:14 INFO 139658144298816] Epoch[6] Batch [10]#011Speed: 90.10 samples/sec#011loss=3.216930\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:14 INFO 139658144298816] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16435.627937316895, \"sum\": 16435.627937316895, \"min\": 16435.627937316895}}, \"EndTime\": 1587686294.566655, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686278.130981}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:14 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.7914176561 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:14 INFO 139658144298816] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=6, train loss <loss>=3.33433261785\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:14 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:14 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_6568c557-6617-4170-9dc0-5e82124ba915-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 208.43815803527832, \"sum\": 208.43815803527832, \"min\": 208.43815803527832}}, \"EndTime\": 1587686294.775489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686294.566706}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/23/2020 23:58:24 INFO 139658144298816] Epoch[7] Batch[0] avg_epoch_loss=3.470984\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=3.47098445892\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:27 INFO 139658144298816] Epoch[7] Batch[5] avg_epoch_loss=3.349670\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:27 INFO 139658144298816] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=3.34966981411\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:27 INFO 139658144298816] Epoch[7] Batch [5]#011Speed: 92.81 samples/sec#011loss=3.349670\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:30 INFO 139658144298816] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15855.191946029663, \"sum\": 15855.191946029663, \"min\": 15855.191946029663}}, \"EndTime\": 1587686310.630789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686294.775542}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:30 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.0406372973 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:30 INFO 139658144298816] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:30 INFO 139658144298816] #quality_metric: host=algo-1, epoch=7, train loss <loss>=3.35716598034\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:30 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:40 INFO 139658144298816] Epoch[8] Batch[0] avg_epoch_loss=3.226882\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=3.22688245773\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:43 INFO 139658144298816] Epoch[8] Batch[5] avg_epoch_loss=3.299976\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:43 INFO 139658144298816] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=3.29997591178\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:43 INFO 139658144298816] Epoch[8] Batch [5]#011Speed: 92.63 samples/sec#011loss=3.299976\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:47 INFO 139658144298816] Epoch[8] Batch[10] avg_epoch_loss=3.261364\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=3.21503076553\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:47 INFO 139658144298816] Epoch[8] Batch [10]#011Speed: 89.34 samples/sec#011loss=3.215031\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:47 INFO 139658144298816] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16453.180074691772, \"sum\": 16453.180074691772, \"min\": 16453.180074691772}}, \"EndTime\": 1587686327.084307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686310.630842}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:47 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.1136427362 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:47 INFO 139658144298816] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=8, train loss <loss>=3.26136448167\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:47 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:47 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_15b49784-0404-4ce0-8ec8-e67f8961b04d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 187.60991096496582, \"sum\": 187.60991096496582, \"min\": 187.60991096496582}}, \"EndTime\": 1587686327.272235, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686327.084357}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:56 INFO 139658144298816] Epoch[9] Batch[0] avg_epoch_loss=3.227475\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:58:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=3.22747540474\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:00 INFO 139658144298816] Epoch[9] Batch[5] avg_epoch_loss=3.240697\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:00 INFO 139658144298816] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=3.24069742362\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:00 INFO 139658144298816] Epoch[9] Batch [5]#011Speed: 91.17 samples/sec#011loss=3.240697\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:04 INFO 139658144298816] Epoch[9] Batch[10] avg_epoch_loss=3.313207\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:04 INFO 139658144298816] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=3.40021910667\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:04 INFO 139658144298816] Epoch[9] Batch [10]#011Speed: 89.39 samples/sec#011loss=3.400219\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:04 INFO 139658144298816] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16807.936906814575, \"sum\": 16807.936906814575, \"min\": 16807.936906814575}}, \"EndTime\": 1587686344.080271, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686327.272284}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:04 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.731496315 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:04 INFO 139658144298816] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:04 INFO 139658144298816] #quality_metric: host=algo-1, epoch=9, train loss <loss>=3.31320727955\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:04 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:13 INFO 139658144298816] Epoch[10] Batch[0] avg_epoch_loss=3.102365\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=3.10236525536\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:17 INFO 139658144298816] Epoch[10] Batch[5] avg_epoch_loss=3.166974\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:17 INFO 139658144298816] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=3.16697410742\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:17 INFO 139658144298816] Epoch[10] Batch [5]#011Speed: 92.49 samples/sec#011loss=3.166974\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:20 INFO 139658144298816] Epoch[10] Batch[10] avg_epoch_loss=3.153326\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=3.13694887161\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:20 INFO 139658144298816] Epoch[10] Batch [10]#011Speed: 89.00 samples/sec#011loss=3.136949\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:20 INFO 139658144298816] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16698.209047317505, \"sum\": 16698.209047317505, \"min\": 16698.209047317505}}, \"EndTime\": 1587686360.778809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686344.080332}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:20 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.0820606186 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:20 INFO 139658144298816] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=10, train loss <loss>=3.15332627296\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:20 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:20 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_c1fb090c-3505-478d-aed6-1a3a376c93fc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 186.35296821594238, \"sum\": 186.35296821594238, \"min\": 186.35296821594238}}, \"EndTime\": 1587686360.965495, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686360.778862}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:30 INFO 139658144298816] Epoch[11] Batch[0] avg_epoch_loss=3.193768\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:30 INFO 139658144298816] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=3.19376778603\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:33 INFO 139658144298816] Epoch[11] Batch[5] avg_epoch_loss=3.120805\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=3.12080534299\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:33 INFO 139658144298816] Epoch[11] Batch [5]#011Speed: 92.06 samples/sec#011loss=3.120805\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:36 INFO 139658144298816] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15733.948945999146, \"sum\": 15733.948945999146, \"min\": 15733.948945999146}}, \"EndTime\": 1587686376.699553, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686360.965552}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:36 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.1041667147 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:36 INFO 139658144298816] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=11, train loss <loss>=3.11336290836\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:36 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:36 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_389ed8a7-bf3f-4eb0-b446-7657a3cf782b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 183.23779106140137, \"sum\": 183.23779106140137, \"min\": 183.23779106140137}}, \"EndTime\": 1587686376.883153, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686376.699604}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/23/2020 23:59:46 INFO 139658144298816] Epoch[12] Batch[0] avg_epoch_loss=2.983557\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:46 INFO 139658144298816] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.98355698586\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:49 INFO 139658144298816] Epoch[12] Batch[5] avg_epoch_loss=3.142137\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=3.14213665326\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:49 INFO 139658144298816] Epoch[12] Batch [5]#011Speed: 91.97 samples/sec#011loss=3.142137\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:52 INFO 139658144298816] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15786.023139953613, \"sum\": 15786.023139953613, \"min\": 15786.023139953613}}, \"EndTime\": 1587686392.66927, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686376.883202}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:52 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.5419856264 records/second\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:52 INFO 139658144298816] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=12, train loss <loss>=3.10308933258\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:52 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/23/2020 23:59:52 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_b1d1e97a-0893-4e68-a6e4-cc8c02ea6974-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 182.47103691101074, \"sum\": 182.47103691101074, \"min\": 182.47103691101074}}, \"EndTime\": 1587686392.852174, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686392.669328}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:02 INFO 139658144298816] Epoch[13] Batch[0] avg_epoch_loss=3.061568\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=3.06156802177\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:05 INFO 139658144298816] Epoch[13] Batch[5] avg_epoch_loss=3.122533\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=3.1225326856\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:05 INFO 139658144298816] Epoch[13] Batch [5]#011Speed: 91.92 samples/sec#011loss=3.122533\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:08 INFO 139658144298816] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15790.997982025146, \"sum\": 15790.997982025146, \"min\": 15790.997982025146}}, \"EndTime\": 1587686408.643273, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686392.852228}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:08 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.6293987743 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:08 INFO 139658144298816] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=13, train loss <loss>=3.10600402355\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:08 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:18 INFO 139658144298816] Epoch[14] Batch[0] avg_epoch_loss=2.830586\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=2.83058595657\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:21 INFO 139658144298816] Epoch[14] Batch[5] avg_epoch_loss=3.043385\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=3.0433849891\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:21 INFO 139658144298816] Epoch[14] Batch [5]#011Speed: 92.43 samples/sec#011loss=3.043385\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:24 INFO 139658144298816] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15799.680948257446, \"sum\": 15799.680948257446, \"min\": 15799.680948257446}}, \"EndTime\": 1587686424.443291, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686408.64333}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:24 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.2537684546 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:24 INFO 139658144298816] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=14, train loss <loss>=3.02466611862\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:24 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:24 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_15f562d9-644c-432f-8718-0a6886908d63-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 207.87310600280762, \"sum\": 207.87310600280762, \"min\": 207.87310600280762}}, \"EndTime\": 1587686424.65157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686424.443349}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:34 INFO 139658144298816] Epoch[15] Batch[0] avg_epoch_loss=3.038363\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=3.03836274147\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:37 INFO 139658144298816] Epoch[15] Batch[5] avg_epoch_loss=2.956232\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.95623203119\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:37 INFO 139658144298816] Epoch[15] Batch [5]#011Speed: 93.22 samples/sec#011loss=2.956232\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:41 INFO 139658144298816] Epoch[15] Batch[10] avg_epoch_loss=2.968550\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=2.98333096504\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:41 INFO 139658144298816] Epoch[15] Batch [10]#011Speed: 90.59 samples/sec#011loss=2.983331\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:41 INFO 139658144298816] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16544.91400718689, \"sum\": 16544.91400718689, \"min\": 16544.91400718689}}, \"EndTime\": 1587686441.196592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686424.651623}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:41 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.8911941215 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:41 INFO 139658144298816] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.96854972839\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:41 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:41 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_cbf76ff8-d3ca-4ab6-bf9b-867d730fa452-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 196.3489055633545, \"sum\": 196.3489055633545, \"min\": 196.3489055633545}}, \"EndTime\": 1587686441.393321, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686441.196653}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:50 INFO 139658144298816] Epoch[16] Batch[0] avg_epoch_loss=2.892659\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:50 INFO 139658144298816] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=2.89265871048\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:54 INFO 139658144298816] Epoch[16] Batch[5] avg_epoch_loss=2.934222\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.93422234058\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:54 INFO 139658144298816] Epoch[16] Batch [5]#011Speed: 90.89 samples/sec#011loss=2.934222\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:57 INFO 139658144298816] Epoch[16] Batch[10] avg_epoch_loss=2.856142\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=2.76244559288\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:57 INFO 139658144298816] Epoch[16] Batch [10]#011Speed: 90.09 samples/sec#011loss=2.762446\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:57 INFO 139658144298816] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16532.879114151, \"sum\": 16532.879114151, \"min\": 16532.879114151}}, \"EndTime\": 1587686457.926308, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686441.393375}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:57 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4968500717 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:57 INFO 139658144298816] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=16, train loss <loss>=2.85614200072\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:57 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:00:58 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_264a96e9-6521-49f6-857b-91cf79036aa1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 194.9748992919922, \"sum\": 194.9748992919922, \"min\": 194.9748992919922}}, \"EndTime\": 1587686458.121622, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686457.926367}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:01:07 INFO 139658144298816] Epoch[17] Batch[0] avg_epoch_loss=2.921350\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:07 INFO 139658144298816] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=2.92135000229\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:11 INFO 139658144298816] Epoch[17] Batch[5] avg_epoch_loss=2.923197\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:11 INFO 139658144298816] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=2.92319746812\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:11 INFO 139658144298816] Epoch[17] Batch [5]#011Speed: 90.97 samples/sec#011loss=2.923197\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:14 INFO 139658144298816] Epoch[17] Batch[10] avg_epoch_loss=2.855245\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=2.77370109558\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:14 INFO 139658144298816] Epoch[17] Batch [10]#011Speed: 89.94 samples/sec#011loss=2.773701\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:14 INFO 139658144298816] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16558.753967285156, \"sum\": 16558.753967285156, \"min\": 16558.753967285156}}, \"EndTime\": 1587686474.680478, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686458.121675}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:14 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.1331995743 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:14 INFO 139658144298816] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=17, train loss <loss>=2.85524457151\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:14 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:14 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_e00645ab-4723-4028-bf3f-13aac621758a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 200.55508613586426, \"sum\": 200.55508613586426, \"min\": 200.55508613586426}}, \"EndTime\": 1587686474.881357, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686474.680528}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:24 INFO 139658144298816] Epoch[18] Batch[0] avg_epoch_loss=3.052327\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=3.05232739449\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:27 INFO 139658144298816] Epoch[18] Batch[5] avg_epoch_loss=2.880221\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:27 INFO 139658144298816] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=2.88022128741\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:27 INFO 139658144298816] Epoch[18] Batch [5]#011Speed: 93.80 samples/sec#011loss=2.880221\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:31 INFO 139658144298816] Epoch[18] Batch[10] avg_epoch_loss=2.931311\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:31 INFO 139658144298816] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=2.99261898994\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:31 INFO 139658144298816] Epoch[18] Batch [10]#011Speed: 91.10 samples/sec#011loss=2.992619\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:31 INFO 139658144298816] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16557.790994644165, \"sum\": 16557.790994644165, \"min\": 16557.790994644165}}, \"EndTime\": 1587686491.439247, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686474.881409}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:31 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.1888978538 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:31 INFO 139658144298816] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:31 INFO 139658144298816] #quality_metric: host=algo-1, epoch=18, train loss <loss>=2.9313111522\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:31 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:40 INFO 139658144298816] Epoch[19] Batch[0] avg_epoch_loss=2.911497\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=2.91149663925\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:44 INFO 139658144298816] Epoch[19] Batch[5] avg_epoch_loss=2.925507\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:44 INFO 139658144298816] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=2.92550722758\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:44 INFO 139658144298816] Epoch[19] Batch [5]#011Speed: 92.66 samples/sec#011loss=2.925507\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:47 INFO 139658144298816] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15708.6820602417, \"sum\": 15708.6820602417, \"min\": 15708.6820602417}}, \"EndTime\": 1587686507.14823, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686491.439293}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:47 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.1952124427 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:47 INFO 139658144298816] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.86906280518\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:47 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:56 INFO 139658144298816] Epoch[20] Batch[0] avg_epoch_loss=2.955410\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:01:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=2.95540952682\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:00 INFO 139658144298816] Epoch[20] Batch[5] avg_epoch_loss=2.905599\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:00 INFO 139658144298816] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=2.90559947491\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:00 INFO 139658144298816] Epoch[20] Batch [5]#011Speed: 93.60 samples/sec#011loss=2.905599\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:02 INFO 139658144298816] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15816.082000732422, \"sum\": 15816.082000732422, \"min\": 15816.082000732422}}, \"EndTime\": 1587686522.964687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686507.148294}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:02 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4532788747 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:02 INFO 139658144298816] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=20, train loss <loss>=2.880712533\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:02 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:12 INFO 139658144298816] Epoch[21] Batch[0] avg_epoch_loss=2.703427\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=2.7034265995\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:15 INFO 139658144298816] Epoch[21] Batch[5] avg_epoch_loss=2.850241\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=2.85024050872\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:15 INFO 139658144298816] Epoch[21] Batch [5]#011Speed: 94.17 samples/sec#011loss=2.850241\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:19 INFO 139658144298816] Epoch[21] Batch[10] avg_epoch_loss=2.807168\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=2.75548157692\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:19 INFO 139658144298816] Epoch[21] Batch [10]#011Speed: 90.31 samples/sec#011loss=2.755482\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:19 INFO 139658144298816] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16453.119039535522, \"sum\": 16453.119039535522, \"min\": 16453.119039535522}}, \"EndTime\": 1587686539.418198, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686522.964752}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:19 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.3844116409 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:19 INFO 139658144298816] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=21, train loss <loss>=2.80716826699\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:19 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:19 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_73646835-8ad1-417b-befb-0c9102f54058-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 211.0280990600586, \"sum\": 211.0280990600586, \"min\": 211.0280990600586}}, \"EndTime\": 1587686539.629602, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686539.418261}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:02:29 INFO 139658144298816] Epoch[22] Batch[0] avg_epoch_loss=2.872275\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.87227511406\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:32 INFO 139658144298816] Epoch[22] Batch[5] avg_epoch_loss=2.911802\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.91180165609\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:32 INFO 139658144298816] Epoch[22] Batch [5]#011Speed: 93.35 samples/sec#011loss=2.911802\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:36 INFO 139658144298816] Epoch[22] Batch[10] avg_epoch_loss=2.908775\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=2.90514235497\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:36 INFO 139658144298816] Epoch[22] Batch [10]#011Speed: 90.65 samples/sec#011loss=2.905142\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:36 INFO 139658144298816] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16492.658853530884, \"sum\": 16492.658853530884, \"min\": 16492.658853530884}}, \"EndTime\": 1587686556.122364, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686539.629658}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:36 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.7144367916 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:36 INFO 139658144298816] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.90877470103\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:36 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:45 INFO 139658144298816] Epoch[23] Batch[0] avg_epoch_loss=2.832833\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=2.83283281326\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:49 INFO 139658144298816] Epoch[23] Batch[5] avg_epoch_loss=2.867690\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.86768964926\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:49 INFO 139658144298816] Epoch[23] Batch [5]#011Speed: 93.72 samples/sec#011loss=2.867690\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:52 INFO 139658144298816] Epoch[23] Batch[10] avg_epoch_loss=2.884112\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=2.90381851196\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:52 INFO 139658144298816] Epoch[23] Batch [10]#011Speed: 90.46 samples/sec#011loss=2.903819\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:52 INFO 139658144298816] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16483.14094543457, \"sum\": 16483.14094543457, \"min\": 16483.14094543457}}, \"EndTime\": 1587686572.605823, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686556.122422}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:52 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.6766898804 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:52 INFO 139658144298816] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=23, train loss <loss>=2.88411185958\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:02:52 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:02 INFO 139658144298816] Epoch[24] Batch[0] avg_epoch_loss=2.913108\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.91310787201\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:05 INFO 139658144298816] Epoch[24] Batch[5] avg_epoch_loss=2.878829\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.87882896264\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:05 INFO 139658144298816] Epoch[24] Batch [5]#011Speed: 94.30 samples/sec#011loss=2.878829\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:08 INFO 139658144298816] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15758.969068527222, \"sum\": 15758.969068527222, \"min\": 15758.969068527222}}, \"EndTime\": 1587686588.365126, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686572.605884}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:08 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.5962705721 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:08 INFO 139658144298816] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.89160759449\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:08 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:17 INFO 139658144298816] Epoch[25] Batch[0] avg_epoch_loss=2.937021\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:17 INFO 139658144298816] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=2.93702101707\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:21 INFO 139658144298816] Epoch[25] Batch[5] avg_epoch_loss=2.854129\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=2.85412895679\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:21 INFO 139658144298816] Epoch[25] Batch [5]#011Speed: 93.74 samples/sec#011loss=2.854129\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:24 INFO 139658144298816] Epoch[25] Batch[10] avg_epoch_loss=2.875885\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=2.90199332237\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:24 INFO 139658144298816] Epoch[25] Batch [10]#011Speed: 90.96 samples/sec#011loss=2.901993\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:24 INFO 139658144298816] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16450.056076049805, \"sum\": 16450.056076049805, \"min\": 16450.056076049805}}, \"EndTime\": 1587686604.815554, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686588.365189}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:24 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.0604348197 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:24 INFO 139658144298816] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.8758854866\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:24 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:34 INFO 139658144298816] Epoch[26] Batch[0] avg_epoch_loss=2.828845\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.82884526253\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:37 INFO 139658144298816] Epoch[26] Batch[5] avg_epoch_loss=2.810763\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.81076256434\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:37 INFO 139658144298816] Epoch[26] Batch [5]#011Speed: 93.10 samples/sec#011loss=2.810763\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:40 INFO 139658144298816] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15743.846893310547, \"sum\": 15743.846893310547, \"min\": 15743.846893310547}}, \"EndTime\": 1587686620.559727, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686604.815615}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:40 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.2059845802 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:40 INFO 139658144298816] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.80660200119\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:40 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:40 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_5fc8bd55-1709-4092-8095-f88f7fbc4127-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 189.55111503601074, \"sum\": 189.55111503601074, \"min\": 189.55111503601074}}, \"EndTime\": 1587686620.749651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686620.559781}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:03:50 INFO 139658144298816] Epoch[27] Batch[0] avg_epoch_loss=2.858387\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:50 INFO 139658144298816] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=2.85838699341\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:53 INFO 139658144298816] Epoch[27] Batch[5] avg_epoch_loss=2.867649\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.86764883995\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:53 INFO 139658144298816] Epoch[27] Batch [5]#011Speed: 92.33 samples/sec#011loss=2.867649\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:57 INFO 139658144298816] Epoch[27] Batch[10] avg_epoch_loss=2.814782\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=2.75134162903\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:57 INFO 139658144298816] Epoch[27] Batch [10]#011Speed: 89.28 samples/sec#011loss=2.751342\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:57 INFO 139658144298816] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16529.6311378479, \"sum\": 16529.6311378479, \"min\": 16529.6311378479}}, \"EndTime\": 1587686637.279386, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686620.749704}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:57 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.8640258859 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:57 INFO 139658144298816] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=27, train loss <loss>=2.81478192589\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:03:57 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:06 INFO 139658144298816] Epoch[28] Batch[0] avg_epoch_loss=2.974078\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=2.97407770157\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:10 INFO 139658144298816] Epoch[28] Batch[5] avg_epoch_loss=2.789226\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:10 INFO 139658144298816] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.78922581673\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:10 INFO 139658144298816] Epoch[28] Batch [5]#011Speed: 92.71 samples/sec#011loss=2.789226\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:13 INFO 139658144298816] Epoch[28] Batch[10] avg_epoch_loss=2.793899\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=2.79950594902\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:13 INFO 139658144298816] Epoch[28] Batch [10]#011Speed: 89.90 samples/sec#011loss=2.799506\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:13 INFO 139658144298816] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16530.267000198364, \"sum\": 16530.267000198364, \"min\": 16530.267000198364}}, \"EndTime\": 1587686653.80994, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686637.279434}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:13 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.8624179436 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:13 INFO 139658144298816] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.79389860413\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:13 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:13 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_48a91381-e714-41bb-91e9-5989957dee19-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 186.4469051361084, \"sum\": 186.4469051361084, \"min\": 186.4469051361084}}, \"EndTime\": 1587686653.996708, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686653.809988}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:23 INFO 139658144298816] Epoch[29] Batch[0] avg_epoch_loss=2.853951\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:23 INFO 139658144298816] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.85395097733\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:26 INFO 139658144298816] Epoch[29] Batch[5] avg_epoch_loss=2.805872\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.80587172508\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:26 INFO 139658144298816] Epoch[29] Batch [5]#011Speed: 92.65 samples/sec#011loss=2.805872\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:28 INFO 139658144298816] processed a total of 573 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14959.408044815063, \"sum\": 14959.408044815063, \"min\": 14959.408044815063}}, \"EndTime\": 1587686668.956219, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686653.996762}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:28 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.3034141577 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:28 INFO 139658144298816] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.80126931932\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:28 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:38 INFO 139658144298816] Epoch[30] Batch[0] avg_epoch_loss=2.619778\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=2.61977815628\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:41 INFO 139658144298816] Epoch[30] Batch[5] avg_epoch_loss=2.752395\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.75239467621\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:41 INFO 139658144298816] Epoch[30] Batch [5]#011Speed: 93.97 samples/sec#011loss=2.752395\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:44 INFO 139658144298816] processed a total of 590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15550.256967544556, \"sum\": 15550.256967544556, \"min\": 15550.256967544556}}, \"EndTime\": 1587686684.506853, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686668.956284}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:44 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=37.9412659962 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:44 INFO 139658144298816] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:44 INFO 139658144298816] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.70941631794\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:44 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:44 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_1d44d793-0e7b-4d53-936e-a8364ca250e7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 204.3130397796631, \"sum\": 204.3130397796631, \"min\": 204.3130397796631}}, \"EndTime\": 1587686684.711594, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686684.506918}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:53 INFO 139658144298816] Epoch[31] Batch[0] avg_epoch_loss=2.810352\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.81035161018\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:57 INFO 139658144298816] Epoch[31] Batch[5] avg_epoch_loss=2.794817\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.79481665293\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:04:57 INFO 139658144298816] Epoch[31] Batch [5]#011Speed: 93.37 samples/sec#011loss=2.794817\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:00 INFO 139658144298816] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15478.56616973877, \"sum\": 15478.56616973877, \"min\": 15478.56616973877}}, \"EndTime\": 1587686700.190263, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686684.711647}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:00 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.6984901079 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:00 INFO 139658144298816] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:00 INFO 139658144298816] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.75602271557\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:00 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:05:09 INFO 139658144298816] Epoch[32] Batch[0] avg_epoch_loss=2.657480\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.65748047829\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:12 INFO 139658144298816] Epoch[32] Batch[5] avg_epoch_loss=2.736866\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.73686615626\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:12 INFO 139658144298816] Epoch[32] Batch [5]#011Speed: 93.88 samples/sec#011loss=2.736866\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:16 INFO 139658144298816] Epoch[32] Batch[10] avg_epoch_loss=2.626421\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:16 INFO 139658144298816] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=2.49388580322\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:16 INFO 139658144298816] Epoch[32] Batch [10]#011Speed: 91.50 samples/sec#011loss=2.493886\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:16 INFO 139658144298816] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16128.764867782593, \"sum\": 16128.764867782593, \"min\": 16128.764867782593}}, \"EndTime\": 1587686716.319337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686700.190313}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:16 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.4244944847 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:16 INFO 139658144298816] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:16 INFO 139658144298816] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.62642054124\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:16 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:16 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_94fdb445-24f4-4d05-a5ec-75b7feb5b498-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 201.57098770141602, \"sum\": 201.57098770141602, \"min\": 201.57098770141602}}, \"EndTime\": 1587686716.521203, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686716.319384}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:25 INFO 139658144298816] Epoch[33] Batch[0] avg_epoch_loss=2.792499\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:25 INFO 139658144298816] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.79249858856\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:29 INFO 139658144298816] Epoch[33] Batch[5] avg_epoch_loss=2.799503\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.79950304826\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:29 INFO 139658144298816] Epoch[33] Batch [5]#011Speed: 90.28 samples/sec#011loss=2.799503\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:32 INFO 139658144298816] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15682.665824890137, \"sum\": 15682.665824890137, \"min\": 15682.665824890137}}, \"EndTime\": 1587686732.203966, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686716.521253}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:32 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.171549281 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:32 INFO 139658144298816] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.77050848007\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:32 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:42 INFO 139658144298816] Epoch[34] Batch[0] avg_epoch_loss=2.692848\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:42 INFO 139658144298816] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=2.69284796715\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:45 INFO 139658144298816] Epoch[34] Batch[5] avg_epoch_loss=2.758725\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.75872472922\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:45 INFO 139658144298816] Epoch[34] Batch [5]#011Speed: 92.23 samples/sec#011loss=2.758725\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:48 INFO 139658144298816] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16285.391092300415, \"sum\": 16285.391092300415, \"min\": 16285.391092300415}}, \"EndTime\": 1587686748.489687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686732.204018}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:48 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.8689989452 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:48 INFO 139658144298816] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:48 INFO 139658144298816] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.71298789978\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:48 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:57 INFO 139658144298816] Epoch[35] Batch[0] avg_epoch_loss=2.577946\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:05:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.57794570923\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:01 INFO 139658144298816] Epoch[35] Batch[5] avg_epoch_loss=2.734615\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.73461548487\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:01 INFO 139658144298816] Epoch[35] Batch [5]#011Speed: 93.11 samples/sec#011loss=2.734615\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:04 INFO 139658144298816] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15742.375135421753, \"sum\": 15742.375135421753, \"min\": 15742.375135421753}}, \"EndTime\": 1587686764.232388, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686748.489742}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:04 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.8921339409 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:04 INFO 139658144298816] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:04 INFO 139658144298816] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.71427865028\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:04 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:13 INFO 139658144298816] Epoch[36] Batch[0] avg_epoch_loss=2.824006\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.82400608063\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:17 INFO 139658144298816] Epoch[36] Batch[5] avg_epoch_loss=2.735318\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:17 INFO 139658144298816] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.73531838258\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:17 INFO 139658144298816] Epoch[36] Batch [5]#011Speed: 93.12 samples/sec#011loss=2.735318\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:19 INFO 139658144298816] processed a total of 595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15665.769815444946, \"sum\": 15665.769815444946, \"min\": 15665.769815444946}}, \"EndTime\": 1587686779.898466, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686764.232441}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:19 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=37.9806693298 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:19 INFO 139658144298816] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.79291250706\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:19 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:29 INFO 139658144298816] Epoch[37] Batch[0] avg_epoch_loss=2.918136\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.91813564301\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:32 INFO 139658144298816] Epoch[37] Batch[5] avg_epoch_loss=2.740233\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=2.74023278554\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:32 INFO 139658144298816] Epoch[37] Batch [5]#011Speed: 93.98 samples/sec#011loss=2.740233\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:06:36 INFO 139658144298816] Epoch[37] Batch[10] avg_epoch_loss=2.673455\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=2.59332056046\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:36 INFO 139658144298816] Epoch[37] Batch [10]#011Speed: 89.46 samples/sec#011loss=2.593321\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:36 INFO 139658144298816] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16424.180030822754, \"sum\": 16424.180030822754, \"min\": 16424.180030822754}}, \"EndTime\": 1587686796.323062, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686779.898531}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:36 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.3929184205 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:36 INFO 139658144298816] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.67345450141\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:36 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:45 INFO 139658144298816] Epoch[38] Batch[0] avg_epoch_loss=2.855675\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.85567450523\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:49 INFO 139658144298816] Epoch[38] Batch[5] avg_epoch_loss=2.726754\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.72675422827\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:49 INFO 139658144298816] Epoch[38] Batch [5]#011Speed: 93.97 samples/sec#011loss=2.726754\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:52 INFO 139658144298816] Epoch[38] Batch[10] avg_epoch_loss=2.719619\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=2.71105623245\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:52 INFO 139658144298816] Epoch[38] Batch [10]#011Speed: 88.98 samples/sec#011loss=2.711056\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:52 INFO 139658144298816] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16408.849954605103, \"sum\": 16408.849954605103, \"min\": 16408.849954605103}}, \"EndTime\": 1587686812.732252, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686796.323125}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:52 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.1250230406 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:52 INFO 139658144298816] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.71961877563\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:06:52 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:02 INFO 139658144298816] Epoch[39] Batch[0] avg_epoch_loss=2.648287\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=2.64828658104\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:05 INFO 139658144298816] Epoch[39] Batch[5] avg_epoch_loss=2.680542\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.68054215113\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:05 INFO 139658144298816] Epoch[39] Batch [5]#011Speed: 93.58 samples/sec#011loss=2.680542\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:09 INFO 139658144298816] Epoch[39] Batch[10] avg_epoch_loss=2.782715\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=2.9053229332\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:09 INFO 139658144298816] Epoch[39] Batch [10]#011Speed: 90.48 samples/sec#011loss=2.905323\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:09 INFO 139658144298816] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16379.302978515625, \"sum\": 16379.302978515625, \"min\": 16379.302978515625}}, \"EndTime\": 1587686829.111876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686812.732311}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:09 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.6229744269 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:09 INFO 139658144298816] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.78271523389\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:09 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:18 INFO 139658144298816] Epoch[40] Batch[0] avg_epoch_loss=2.879117\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.87911748886\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:21 INFO 139658144298816] Epoch[40] Batch[5] avg_epoch_loss=2.762244\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.76224394639\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:21 INFO 139658144298816] Epoch[40] Batch [5]#011Speed: 94.08 samples/sec#011loss=2.762244\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:24 INFO 139658144298816] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15615.002155303955, \"sum\": 15615.002155303955, \"min\": 15615.002155303955}}, \"EndTime\": 1587686844.727198, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686829.111932}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:24 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.9366907195 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:24 INFO 139658144298816] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.69078965187\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:24 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:34 INFO 139658144298816] Epoch[41] Batch[0] avg_epoch_loss=2.752526\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.75252556801\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:37 INFO 139658144298816] Epoch[41] Batch[5] avg_epoch_loss=2.748794\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.74879388014\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:37 INFO 139658144298816] Epoch[41] Batch [5]#011Speed: 94.01 samples/sec#011loss=2.748794\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:40 INFO 139658144298816] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15528.466939926147, \"sum\": 15528.466939926147, \"min\": 15528.466939926147}}, \"EndTime\": 1587686860.256036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686844.72726}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:40 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.0248775074 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:40 INFO 139658144298816] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.750872612\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:40 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:49 INFO 139658144298816] Epoch[42] Batch[0] avg_epoch_loss=2.841402\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.84140229225\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:53 INFO 139658144298816] Epoch[42] Batch[5] avg_epoch_loss=2.786764\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.78676354885\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:53 INFO 139658144298816] Epoch[42] Batch [5]#011Speed: 93.10 samples/sec#011loss=2.786764\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:56 INFO 139658144298816] Epoch[42] Batch[10] avg_epoch_loss=2.711946\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.62216448784\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:56 INFO 139658144298816] Epoch[42] Batch [10]#011Speed: 90.67 samples/sec#011loss=2.622164\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:56 INFO 139658144298816] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16428.968906402588, \"sum\": 16428.968906402588, \"min\": 16428.968906402588}}, \"EndTime\": 1587686876.685369, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686860.256097}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:56 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.1988411292 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:56 INFO 139658144298816] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.71194579385\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:07:56 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:08:06 INFO 139658144298816] Epoch[43] Batch[0] avg_epoch_loss=2.709767\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.70976734161\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:09 INFO 139658144298816] Epoch[43] Batch[5] avg_epoch_loss=2.661862\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.66186217467\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:09 INFO 139658144298816] Epoch[43] Batch [5]#011Speed: 93.47 samples/sec#011loss=2.661862\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:13 INFO 139658144298816] Epoch[43] Batch[10] avg_epoch_loss=2.711381\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.7708029747\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:13 INFO 139658144298816] Epoch[43] Batch [10]#011Speed: 90.26 samples/sec#011loss=2.770803\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:13 INFO 139658144298816] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16440.365076065063, \"sum\": 16440.365076065063, \"min\": 16440.365076065063}}, \"EndTime\": 1587686893.126074, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686876.68543}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:13 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.5974466249 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:13 INFO 139658144298816] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.71138072014\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:13 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:22 INFO 139658144298816] Epoch[44] Batch[0] avg_epoch_loss=2.641665\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.64166545868\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:26 INFO 139658144298816] Epoch[44] Batch[5] avg_epoch_loss=2.704044\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.70404398441\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:26 INFO 139658144298816] Epoch[44] Batch [5]#011Speed: 92.51 samples/sec#011loss=2.704044\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:29 INFO 139658144298816] Epoch[44] Batch[10] avg_epoch_loss=2.639927\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=2.5629860878\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:29 INFO 139658144298816] Epoch[44] Batch [10]#011Speed: 89.76 samples/sec#011loss=2.562986\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:29 INFO 139658144298816] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16571.979999542236, \"sum\": 16571.979999542236, \"min\": 16571.979999542236}}, \"EndTime\": 1587686909.698398, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686893.126135}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:29 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.1881091495 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:29 INFO 139658144298816] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.63992675868\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:29 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:39 INFO 139658144298816] Epoch[45] Batch[0] avg_epoch_loss=2.691344\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:39 INFO 139658144298816] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=2.69134402275\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:42 INFO 139658144298816] Epoch[45] Batch[5] avg_epoch_loss=2.685339\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:42 INFO 139658144298816] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=2.68533861637\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:42 INFO 139658144298816] Epoch[45] Batch [5]#011Speed: 92.65 samples/sec#011loss=2.685339\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:46 INFO 139658144298816] Epoch[45] Batch[10] avg_epoch_loss=2.663097\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:46 INFO 139658144298816] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=2.63640804291\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:46 INFO 139658144298816] Epoch[45] Batch [10]#011Speed: 89.80 samples/sec#011loss=2.636408\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:46 INFO 139658144298816] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16562.95895576477, \"sum\": 16562.95895576477, \"min\": 16562.95895576477}}, \"EndTime\": 1587686926.261683, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686909.698456}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:46 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.1232740938 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:46 INFO 139658144298816] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:46 INFO 139658144298816] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.66309744662\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:46 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:55 INFO 139658144298816] Epoch[46] Batch[0] avg_epoch_loss=2.770109\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:55 INFO 139658144298816] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.77010941505\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:59 INFO 139658144298816] Epoch[46] Batch[5] avg_epoch_loss=2.783444\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:59 INFO 139658144298816] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=2.78344412645\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:08:59 INFO 139658144298816] Epoch[46] Batch [5]#011Speed: 93.95 samples/sec#011loss=2.783444\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:02 INFO 139658144298816] Epoch[46] Batch[10] avg_epoch_loss=2.713773\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.63016734123\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:02 INFO 139658144298816] Epoch[46] Batch [10]#011Speed: 90.88 samples/sec#011loss=2.630167\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:02 INFO 139658144298816] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16323.571920394897, \"sum\": 16323.571920394897, \"min\": 16323.571920394897}}, \"EndTime\": 1587686942.585516, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686926.26173}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:02 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.2898004384 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:02 INFO 139658144298816] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.71377286044\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:02 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:12 INFO 139658144298816] Epoch[47] Batch[0] avg_epoch_loss=2.776406\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.77640557289\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:15 INFO 139658144298816] Epoch[47] Batch[5] avg_epoch_loss=2.675147\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.67514657974\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:15 INFO 139658144298816] Epoch[47] Batch [5]#011Speed: 91.27 samples/sec#011loss=2.675147\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:19 INFO 139658144298816] Epoch[47] Batch[10] avg_epoch_loss=2.691692\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=2.7115468502\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:19 INFO 139658144298816] Epoch[47] Batch [10]#011Speed: 88.98 samples/sec#011loss=2.711547\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:19 INFO 139658144298816] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16545.199155807495, \"sum\": 16545.199155807495, \"min\": 16545.199155807495}}, \"EndTime\": 1587686959.131031, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686942.585564}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:19 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.1597897507 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:19 INFO 139658144298816] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.69169215723\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:19 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:09:28 INFO 139658144298816] Epoch[48] Batch[0] avg_epoch_loss=2.526457\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.52645730972\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:32 INFO 139658144298816] Epoch[48] Batch[5] avg_epoch_loss=2.659887\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.65988747279\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:32 INFO 139658144298816] Epoch[48] Batch [5]#011Speed: 93.67 samples/sec#011loss=2.659887\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:34 INFO 139658144298816] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15798.113107681274, \"sum\": 15798.113107681274, \"min\": 15798.113107681274}}, \"EndTime\": 1587686974.929434, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686959.131081}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:34 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.3843295761 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:34 INFO 139658144298816] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.64526114464\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:34 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:44 INFO 139658144298816] Epoch[49] Batch[0] avg_epoch_loss=2.560991\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:44 INFO 139658144298816] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.56099057198\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:47 INFO 139658144298816] Epoch[49] Batch[5] avg_epoch_loss=2.600989\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.60098874569\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:47 INFO 139658144298816] Epoch[49] Batch [5]#011Speed: 94.13 samples/sec#011loss=2.600989\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:50 INFO 139658144298816] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15630.277872085571, \"sum\": 15630.277872085571, \"min\": 15630.277872085571}}, \"EndTime\": 1587686990.560087, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686974.929498}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:50 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.2185114556 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:50 INFO 139658144298816] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:50 INFO 139658144298816] #quality_metric: host=algo-1, epoch=49, train loss <loss>=2.62945599556\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:50 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:59 INFO 139658144298816] Epoch[50] Batch[0] avg_epoch_loss=2.604327\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:09:59 INFO 139658144298816] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.60432720184\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:03 INFO 139658144298816] Epoch[50] Batch[5] avg_epoch_loss=2.624792\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:03 INFO 139658144298816] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.62479213874\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:03 INFO 139658144298816] Epoch[50] Batch [5]#011Speed: 93.32 samples/sec#011loss=2.624792\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:06 INFO 139658144298816] Epoch[50] Batch[10] avg_epoch_loss=2.652156\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.68499155045\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:06 INFO 139658144298816] Epoch[50] Batch [10]#011Speed: 89.46 samples/sec#011loss=2.684992\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:06 INFO 139658144298816] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16434.417963027954, \"sum\": 16434.417963027954, \"min\": 16434.417963027954}}, \"EndTime\": 1587687006.994882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587686990.560153}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:06 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4901211638 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:06 INFO 139658144298816] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.65215550769\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:06 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:16 INFO 139658144298816] Epoch[51] Batch[0] avg_epoch_loss=2.627994\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:16 INFO 139658144298816] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.62799406052\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:19 INFO 139658144298816] Epoch[51] Batch[5] avg_epoch_loss=2.672285\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.67228464286\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:19 INFO 139658144298816] Epoch[51] Batch [5]#011Speed: 92.65 samples/sec#011loss=2.672285\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:22 INFO 139658144298816] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15790.648937225342, \"sum\": 15790.648937225342, \"min\": 15790.648937225342}}, \"EndTime\": 1587687022.785889, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687006.994929}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:22 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.4034006568 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:22 INFO 139658144298816] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.68671295643\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:22 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:32 INFO 139658144298816] Epoch[52] Batch[0] avg_epoch_loss=2.652524\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.65252447128\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:35 INFO 139658144298816] Epoch[52] Batch[5] avg_epoch_loss=2.629868\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:35 INFO 139658144298816] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.62986803055\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:35 INFO 139658144298816] Epoch[52] Batch [5]#011Speed: 93.29 samples/sec#011loss=2.629868\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:38 INFO 139658144298816] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15743.547916412354, \"sum\": 15743.547916412354, \"min\": 15743.547916412354}}, \"EndTime\": 1587687038.529843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687022.785956}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:38 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.0161947972 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:38 INFO 139658144298816] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.67143654823\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:38 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:48 INFO 139658144298816] Epoch[53] Batch[0] avg_epoch_loss=2.581985\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:48 INFO 139658144298816] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.58198523521\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:51 INFO 139658144298816] Epoch[53] Batch[5] avg_epoch_loss=2.632687\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:51 INFO 139658144298816] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.6326867342\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:51 INFO 139658144298816] Epoch[53] Batch [5]#011Speed: 92.69 samples/sec#011loss=2.632687\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:55 INFO 139658144298816] Epoch[53] Batch[10] avg_epoch_loss=2.617563\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:55 INFO 139658144298816] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=2.5994146347\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:55 INFO 139658144298816] Epoch[53] Batch [10]#011Speed: 90.44 samples/sec#011loss=2.599415\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:55 INFO 139658144298816] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16535.88581085205, \"sum\": 16535.88581085205, \"min\": 16535.88581085205}}, \"EndTime\": 1587687055.066064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687038.529895}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:55 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.2153707402 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:55 INFO 139658144298816] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:55 INFO 139658144298816] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.61756305261\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:55 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:10:55 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_22034ea2-7e46-48ed-b012-0e77089365d5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 203.64904403686523, \"sum\": 203.64904403686523, \"min\": 203.64904403686523}}, \"EndTime\": 1587687055.270091, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687055.066115}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:11:04 INFO 139658144298816] Epoch[54] Batch[0] avg_epoch_loss=2.683609\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:04 INFO 139658144298816] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.68360900879\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:08 INFO 139658144298816] Epoch[54] Batch[5] avg_epoch_loss=2.694812\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.69481237729\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:08 INFO 139658144298816] Epoch[54] Batch [5]#011Speed: 93.31 samples/sec#011loss=2.694812\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:10 INFO 139658144298816] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15689.12386894226, \"sum\": 15689.12386894226, \"min\": 15689.12386894226}}, \"EndTime\": 1587687070.95932, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687055.270146}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:10 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.5176277502 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:10 INFO 139658144298816] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:10 INFO 139658144298816] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.68215014935\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:10 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:20 INFO 139658144298816] Epoch[55] Batch[0] avg_epoch_loss=2.637291\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.63729071617\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:23 INFO 139658144298816] Epoch[55] Batch[5] avg_epoch_loss=2.634890\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:23 INFO 139658144298816] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.63488976161\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:23 INFO 139658144298816] Epoch[55] Batch [5]#011Speed: 94.31 samples/sec#011loss=2.634890\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:26 INFO 139658144298816] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15784.271955490112, \"sum\": 15784.271955490112, \"min\": 15784.271955490112}}, \"EndTime\": 1587687086.743917, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687070.959371}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:26 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.419747074 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:26 INFO 139658144298816] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.64701735973\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:26 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:36 INFO 139658144298816] Epoch[56] Batch[0] avg_epoch_loss=2.621276\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.62127637863\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:39 INFO 139658144298816] Epoch[56] Batch[5] avg_epoch_loss=2.629886\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:39 INFO 139658144298816] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.62988591194\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:39 INFO 139658144298816] Epoch[56] Batch [5]#011Speed: 93.00 samples/sec#011loss=2.629886\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:42 INFO 139658144298816] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15681.043863296509, \"sum\": 15681.043863296509, \"min\": 15681.043863296509}}, \"EndTime\": 1587687102.425329, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687086.743981}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:42 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.5583042434 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:42 INFO 139658144298816] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:42 INFO 139658144298816] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.63360395432\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:42 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:51 INFO 139658144298816] Epoch[57] Batch[0] avg_epoch_loss=2.536063\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:51 INFO 139658144298816] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.53606343269\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:55 INFO 139658144298816] Epoch[57] Batch[5] avg_epoch_loss=2.661878\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:55 INFO 139658144298816] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.66187755267\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:55 INFO 139658144298816] Epoch[57] Batch [5]#011Speed: 93.11 samples/sec#011loss=2.661878\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:58 INFO 139658144298816] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15729.531049728394, \"sum\": 15729.531049728394, \"min\": 15729.531049728394}}, \"EndTime\": 1587687118.155227, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687102.425385}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:58 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.843953082 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:58 INFO 139658144298816] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:58 INFO 139658144298816] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.66852705479\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:11:58 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:07 INFO 139658144298816] Epoch[58] Batch[0] avg_epoch_loss=2.796382\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:07 INFO 139658144298816] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.79638195038\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:11 INFO 139658144298816] Epoch[58] Batch[5] avg_epoch_loss=2.690291\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:11 INFO 139658144298816] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.69029080868\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:11 INFO 139658144298816] Epoch[58] Batch [5]#011Speed: 92.69 samples/sec#011loss=2.690291\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:14 INFO 139658144298816] Epoch[58] Batch[10] avg_epoch_loss=2.687892\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.68501420021\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:14 INFO 139658144298816] Epoch[58] Batch [10]#011Speed: 89.97 samples/sec#011loss=2.685014\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:14 INFO 139658144298816] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16541.89705848694, \"sum\": 16541.89705848694, \"min\": 16541.89705848694}}, \"EndTime\": 1587687134.69743, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687118.155277}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:14 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.6566914865 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:14 INFO 139658144298816] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.68789235028\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:14 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:24 INFO 139658144298816] Epoch[59] Batch[0] avg_epoch_loss=2.448879\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.44887852669\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:27 INFO 139658144298816] Epoch[59] Batch[5] avg_epoch_loss=2.639339\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:27 INFO 139658144298816] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.63933893045\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:27 INFO 139658144298816] Epoch[59] Batch [5]#011Speed: 92.81 samples/sec#011loss=2.639339\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:30 INFO 139658144298816] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15747.17402458191, \"sum\": 15747.17402458191, \"min\": 15747.17402458191}}, \"EndTime\": 1587687150.444902, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687134.697481}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:30 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.6894267233 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:30 INFO 139658144298816] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:30 INFO 139658144298816] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.64978647232\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:30 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:12:39 INFO 139658144298816] Epoch[60] Batch[0] avg_epoch_loss=2.503608\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:39 INFO 139658144298816] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.50360751152\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:43 INFO 139658144298816] Epoch[60] Batch[5] avg_epoch_loss=2.619295\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:43 INFO 139658144298816] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.61929476261\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:43 INFO 139658144298816] Epoch[60] Batch [5]#011Speed: 93.98 samples/sec#011loss=2.619295\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:46 INFO 139658144298816] Epoch[60] Batch[10] avg_epoch_loss=2.588974\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:46 INFO 139658144298816] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.5525888443\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:46 INFO 139658144298816] Epoch[60] Batch [10]#011Speed: 89.60 samples/sec#011loss=2.552589\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:46 INFO 139658144298816] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16493.24607849121, \"sum\": 16493.24607849121, \"min\": 16493.24607849121}}, \"EndTime\": 1587687166.938521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687150.444965}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:46 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.1067035483 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:46 INFO 139658144298816] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:46 INFO 139658144298816] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.58897389065\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:46 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:47 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_dc28f54a-b875-4136-855f-2d33b578fef1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 196.61712646484375, \"sum\": 196.61712646484375, \"min\": 196.61712646484375}}, \"EndTime\": 1587687167.135538, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687166.938583}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:56 INFO 139658144298816] Epoch[61] Batch[0] avg_epoch_loss=2.683927\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:12:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.68392658234\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:00 INFO 139658144298816] Epoch[61] Batch[5] avg_epoch_loss=2.684886\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:00 INFO 139658144298816] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.68488566081\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:00 INFO 139658144298816] Epoch[61] Batch [5]#011Speed: 93.19 samples/sec#011loss=2.684886\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:02 INFO 139658144298816] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15769.744873046875, \"sum\": 15769.744873046875, \"min\": 15769.744873046875}}, \"EndTime\": 1587687182.905389, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687167.135592}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:02 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.0765162073 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:02 INFO 139658144298816] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.66655642986\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:02 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:12 INFO 139658144298816] Epoch[62] Batch[0] avg_epoch_loss=2.596204\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.5962035656\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:15 INFO 139658144298816] Epoch[62] Batch[5] avg_epoch_loss=2.635908\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.6359077692\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:15 INFO 139658144298816] Epoch[62] Batch [5]#011Speed: 93.01 samples/sec#011loss=2.635908\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:19 INFO 139658144298816] Epoch[62] Batch[10] avg_epoch_loss=2.555022\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.45795974731\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:19 INFO 139658144298816] Epoch[62] Batch [10]#011Speed: 89.53 samples/sec#011loss=2.457960\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:19 INFO 139658144298816] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16557.932138442993, \"sum\": 16557.932138442993, \"min\": 16557.932138442993}}, \"EndTime\": 1587687199.463718, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687182.90545}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:19 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.3163089443 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:19 INFO 139658144298816] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.55502230471\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:19 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:19 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_f30ccc33-a0e9-44d0-a35d-36e5dffb12a9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 185.66107749938965, \"sum\": 185.66107749938965, \"min\": 185.66107749938965}}, \"EndTime\": 1587687199.649698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687199.463772}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:29 INFO 139658144298816] Epoch[63] Batch[0] avg_epoch_loss=2.530850\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.53084969521\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:32 INFO 139658144298816] Epoch[63] Batch[5] avg_epoch_loss=2.647504\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.64750381311\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:32 INFO 139658144298816] Epoch[63] Batch [5]#011Speed: 92.79 samples/sec#011loss=2.647504\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:36 INFO 139658144298816] Epoch[63] Batch[10] avg_epoch_loss=2.584050\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.50790448189\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:36 INFO 139658144298816] Epoch[63] Batch [10]#011Speed: 90.76 samples/sec#011loss=2.507904\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:36 INFO 139658144298816] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16457.090854644775, \"sum\": 16457.090854644775, \"min\": 16457.090854644775}}, \"EndTime\": 1587687216.106882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687199.649746}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:36 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.8940398231 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:36 INFO 139658144298816] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.58404957164\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:36 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:45 INFO 139658144298816] Epoch[64] Batch[0] avg_epoch_loss=2.603644\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.60364437103\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:48 INFO 139658144298816] Epoch[64] Batch[5] avg_epoch_loss=2.664263\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:48 INFO 139658144298816] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.66426304976\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:48 INFO 139658144298816] Epoch[64] Batch [5]#011Speed: 93.52 samples/sec#011loss=2.664263\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:51 INFO 139658144298816] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15696.928024291992, \"sum\": 15696.928024291992, \"min\": 15696.928024291992}}, \"EndTime\": 1587687231.804076, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687216.106932}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:51 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.6447010855 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:51 INFO 139658144298816] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:51 INFO 139658144298816] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.62401976585\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:13:51 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:14:01 INFO 139658144298816] Epoch[65] Batch[0] avg_epoch_loss=2.569737\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.56973671913\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:04 INFO 139658144298816] Epoch[65] Batch[5] avg_epoch_loss=2.623156\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:04 INFO 139658144298816] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.62315555414\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:04 INFO 139658144298816] Epoch[65] Batch [5]#011Speed: 93.99 samples/sec#011loss=2.623156\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:08 INFO 139658144298816] Epoch[65] Batch[10] avg_epoch_loss=2.606568\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=2.586662817\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:08 INFO 139658144298816] Epoch[65] Batch [10]#011Speed: 90.88 samples/sec#011loss=2.586663\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:08 INFO 139658144298816] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16486.682891845703, \"sum\": 16486.682891845703, \"min\": 16486.682891845703}}, \"EndTime\": 1587687248.291068, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687231.804127}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:08 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.548468449 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:08 INFO 139658144298816] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.60656794635\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:08 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:17 INFO 139658144298816] Epoch[66] Batch[0] avg_epoch_loss=2.600810\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:17 INFO 139658144298816] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=2.60080981255\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:21 INFO 139658144298816] Epoch[66] Batch[5] avg_epoch_loss=2.608670\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.60866983732\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:21 INFO 139658144298816] Epoch[66] Batch [5]#011Speed: 93.77 samples/sec#011loss=2.608670\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:23 INFO 139658144298816] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15700.645923614502, \"sum\": 15700.645923614502, \"min\": 15700.645923614502}}, \"EndTime\": 1587687263.992048, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687248.291128}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:23 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.2529131655 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:23 INFO 139658144298816] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:23 INFO 139658144298816] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.60399363041\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:23 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:33 INFO 139658144298816] Epoch[67] Batch[0] avg_epoch_loss=2.575069\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.57506918907\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:36 INFO 139658144298816] Epoch[67] Batch[5] avg_epoch_loss=2.591694\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=2.59169427554\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:36 INFO 139658144298816] Epoch[67] Batch [5]#011Speed: 92.71 samples/sec#011loss=2.591694\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:40 INFO 139658144298816] Epoch[67] Batch[10] avg_epoch_loss=2.552372\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.50518622398\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:40 INFO 139658144298816] Epoch[67] Batch [10]#011Speed: 89.59 samples/sec#011loss=2.505186\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:40 INFO 139658144298816] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16435.601949691772, \"sum\": 16435.601949691772, \"min\": 16435.601949691772}}, \"EndTime\": 1587687280.428019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687263.992101}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:40 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.5480835083 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:40 INFO 139658144298816] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.55237243392\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:40 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:40 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_713463d2-a3a9-43c7-addc-11bf6b2bf970-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 243.5128688812256, \"sum\": 243.5128688812256, \"min\": 243.5128688812256}}, \"EndTime\": 1587687280.671929, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687280.428079}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:50 INFO 139658144298816] Epoch[68] Batch[0] avg_epoch_loss=2.698217\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:50 INFO 139658144298816] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.69821715355\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:53 INFO 139658144298816] Epoch[68] Batch[5] avg_epoch_loss=2.585674\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.58567420642\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:53 INFO 139658144298816] Epoch[68] Batch [5]#011Speed: 93.91 samples/sec#011loss=2.585674\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:57 INFO 139658144298816] Epoch[68] Batch[10] avg_epoch_loss=2.600497\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.6182849884\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:57 INFO 139658144298816] Epoch[68] Batch [10]#011Speed: 89.79 samples/sec#011loss=2.618285\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:57 INFO 139658144298816] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16461.95888519287, \"sum\": 16461.95888519287, \"min\": 16461.95888519287}}, \"EndTime\": 1587687297.133987, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687280.671978}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:57 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.2137159653 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:57 INFO 139658144298816] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.60049728914\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:14:57 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:06 INFO 139658144298816] Epoch[69] Batch[0] avg_epoch_loss=2.556879\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.55687856674\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:10 INFO 139658144298816] Epoch[69] Batch[5] avg_epoch_loss=2.568433\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:10 INFO 139658144298816] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.56843328476\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:10 INFO 139658144298816] Epoch[69] Batch [5]#011Speed: 93.30 samples/sec#011loss=2.568433\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:12 INFO 139658144298816] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15723.818063735962, \"sum\": 15723.818063735962, \"min\": 15723.818063735962}}, \"EndTime\": 1587687312.858128, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687297.134044}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:12 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=37.776834524 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:12 INFO 139658144298816] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.56861772537\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:12 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:15:22 INFO 139658144298816] Epoch[70] Batch[0] avg_epoch_loss=2.627469\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=2.62746906281\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:25 INFO 139658144298816] Epoch[70] Batch[5] avg_epoch_loss=2.655460\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:25 INFO 139658144298816] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=2.65546011925\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:25 INFO 139658144298816] Epoch[70] Batch [5]#011Speed: 93.59 samples/sec#011loss=2.655460\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:29 INFO 139658144298816] Epoch[70] Batch[10] avg_epoch_loss=2.572034\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=2.47192211151\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:29 INFO 139658144298816] Epoch[70] Batch [10]#011Speed: 90.05 samples/sec#011loss=2.471922\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:29 INFO 139658144298816] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16516.33906364441, \"sum\": 16516.33906364441, \"min\": 16516.33906364441}}, \"EndTime\": 1587687329.374859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687312.858203}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:29 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.2024065742 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:29 INFO 139658144298816] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=70, train loss <loss>=2.57203375209\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:29 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:38 INFO 139658144298816] Epoch[71] Batch[0] avg_epoch_loss=2.593350\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=2.59334969521\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:42 INFO 139658144298816] Epoch[71] Batch[5] avg_epoch_loss=2.601154\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:42 INFO 139658144298816] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=2.60115396976\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:42 INFO 139658144298816] Epoch[71] Batch [5]#011Speed: 92.40 samples/sec#011loss=2.601154\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:45 INFO 139658144298816] Epoch[71] Batch[10] avg_epoch_loss=2.543422\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=2.47414464951\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:45 INFO 139658144298816] Epoch[71] Batch [10]#011Speed: 90.40 samples/sec#011loss=2.474145\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:45 INFO 139658144298816] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16518.852949142456, \"sum\": 16518.852949142456, \"min\": 16518.852949142456}}, \"EndTime\": 1587687345.894038, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687329.374916}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:45 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.5595325515 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:45 INFO 139658144298816] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=71, train loss <loss>=2.54342246056\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:45 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:46 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_d82905ff-4559-4d7e-a642-be970db23158-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 210.76488494873047, \"sum\": 210.76488494873047, \"min\": 210.76488494873047}}, \"EndTime\": 1587687346.105108, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687345.894089}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:55 INFO 139658144298816] Epoch[72] Batch[0] avg_epoch_loss=2.613933\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:55 INFO 139658144298816] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=2.61393332481\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:59 INFO 139658144298816] Epoch[72] Batch[5] avg_epoch_loss=2.609571\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:59 INFO 139658144298816] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=2.60957101981\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:15:59 INFO 139658144298816] Epoch[72] Batch [5]#011Speed: 92.30 samples/sec#011loss=2.609571\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:02 INFO 139658144298816] Epoch[72] Batch[10] avg_epoch_loss=2.603470\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=2.59614953995\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:02 INFO 139658144298816] Epoch[72] Batch [10]#011Speed: 89.55 samples/sec#011loss=2.596150\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:02 INFO 139658144298816] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16652.465105056763, \"sum\": 16652.465105056763, \"min\": 16652.465105056763}}, \"EndTime\": 1587687362.757671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687346.105158}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:02 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.3149962103 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:02 INFO 139658144298816] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=72, train loss <loss>=2.60347034714\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:02 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:12 INFO 139658144298816] Epoch[73] Batch[0] avg_epoch_loss=2.609688\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=2.60968828201\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:15 INFO 139658144298816] Epoch[73] Batch[5] avg_epoch_loss=2.612868\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=2.61286799113\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:15 INFO 139658144298816] Epoch[73] Batch [5]#011Speed: 93.72 samples/sec#011loss=2.612868\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:19 INFO 139658144298816] Epoch[73] Batch[10] avg_epoch_loss=2.632084\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=2.65514426231\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:19 INFO 139658144298816] Epoch[73] Batch [10]#011Speed: 90.48 samples/sec#011loss=2.655144\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:19 INFO 139658144298816] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16542.809009552002, \"sum\": 16542.809009552002, \"min\": 16542.809009552002}}, \"EndTime\": 1587687379.300795, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687362.757728}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:19 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.8686500726 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:19 INFO 139658144298816] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=73, train loss <loss>=2.63208447803\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:19 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:28 INFO 139658144298816] Epoch[74] Batch[0] avg_epoch_loss=2.623133\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=2.62313342094\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:32 INFO 139658144298816] Epoch[74] Batch[5] avg_epoch_loss=2.617526\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=2.61752569675\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:32 INFO 139658144298816] Epoch[74] Batch [5]#011Speed: 92.39 samples/sec#011loss=2.617526\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:35 INFO 139658144298816] Epoch[74] Batch[10] avg_epoch_loss=2.616683\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:35 INFO 139658144298816] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=2.61567211151\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:35 INFO 139658144298816] Epoch[74] Batch [10]#011Speed: 90.48 samples/sec#011loss=2.615672\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:35 INFO 139658144298816] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16661.173105239868, \"sum\": 16661.173105239868, \"min\": 16661.173105239868}}, \"EndTime\": 1587687395.962289, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687379.300854}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:35 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.6729098815 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:35 INFO 139658144298816] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:35 INFO 139658144298816] #quality_metric: host=algo-1, epoch=74, train loss <loss>=2.61668315801\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:35 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:16:45 INFO 139658144298816] Epoch[75] Batch[0] avg_epoch_loss=2.630316\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=2.63031578064\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:48 INFO 139658144298816] Epoch[75] Batch[5] avg_epoch_loss=2.555544\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:48 INFO 139658144298816] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=2.55554413795\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:48 INFO 139658144298816] Epoch[75] Batch [5]#011Speed: 92.79 samples/sec#011loss=2.555544\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:51 INFO 139658144298816] processed a total of 589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15714.869976043701, \"sum\": 15714.869976043701, \"min\": 15714.869976043701}}, \"EndTime\": 1587687411.677437, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687395.962336}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:51 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=37.480250647 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:51 INFO 139658144298816] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:51 INFO 139658144298816] #quality_metric: host=algo-1, epoch=75, train loss <loss>=2.51437404156\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:51 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:16:51 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_2666d88b-3888-415b-846c-4a7bbb1f8edf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 181.7641258239746, \"sum\": 181.7641258239746, \"min\": 181.7641258239746}}, \"EndTime\": 1587687411.859532, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687411.677487}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:01 INFO 139658144298816] Epoch[76] Batch[0] avg_epoch_loss=2.527788\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=2.52778816223\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:04 INFO 139658144298816] Epoch[76] Batch[5] avg_epoch_loss=2.547776\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:04 INFO 139658144298816] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=2.5477763017\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:04 INFO 139658144298816] Epoch[76] Batch [5]#011Speed: 92.89 samples/sec#011loss=2.547776\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:08 INFO 139658144298816] Epoch[76] Batch[10] avg_epoch_loss=2.538536\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=2.52744693756\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:08 INFO 139658144298816] Epoch[76] Batch [10]#011Speed: 90.64 samples/sec#011loss=2.527447\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:08 INFO 139658144298816] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16543.751001358032, \"sum\": 16543.751001358032, \"min\": 16543.751001358032}}, \"EndTime\": 1587687428.403382, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687411.859583}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:08 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.1633546837 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:08 INFO 139658144298816] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=76, train loss <loss>=2.53853568164\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:08 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:17 INFO 139658144298816] Epoch[77] Batch[0] avg_epoch_loss=2.510787\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:17 INFO 139658144298816] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=2.51078653336\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:21 INFO 139658144298816] Epoch[77] Batch[5] avg_epoch_loss=2.556889\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=2.55688858032\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:21 INFO 139658144298816] Epoch[77] Batch [5]#011Speed: 94.16 samples/sec#011loss=2.556889\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:24 INFO 139658144298816] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15772.142887115479, \"sum\": 15772.142887115479, \"min\": 15772.142887115479}}, \"EndTime\": 1587687444.175873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687428.403444}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:24 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.3874303091 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:24 INFO 139658144298816] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=77, train loss <loss>=2.55908977985\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:24 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:33 INFO 139658144298816] Epoch[78] Batch[0] avg_epoch_loss=2.564101\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=2.56410050392\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:37 INFO 139658144298816] Epoch[78] Batch[5] avg_epoch_loss=2.602670\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=2.6026703914\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:37 INFO 139658144298816] Epoch[78] Batch [5]#011Speed: 93.94 samples/sec#011loss=2.602670\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:40 INFO 139658144298816] Epoch[78] Batch[10] avg_epoch_loss=2.591839\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=2.57884225845\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:40 INFO 139658144298816] Epoch[78] Batch [10]#011Speed: 91.18 samples/sec#011loss=2.578842\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:40 INFO 139658144298816] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16485.98289489746, \"sum\": 16485.98289489746, \"min\": 16485.98289489746}}, \"EndTime\": 1587687460.662226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687444.175937}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:40 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=42.0961833675 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:40 INFO 139658144298816] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=78, train loss <loss>=2.59183942188\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:40 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:49 INFO 139658144298816] Epoch[79] Batch[0] avg_epoch_loss=2.465825\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=2.46582484245\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:53 INFO 139658144298816] Epoch[79] Batch[5] avg_epoch_loss=2.560208\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=2.56020812194\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:53 INFO 139658144298816] Epoch[79] Batch [5]#011Speed: 92.04 samples/sec#011loss=2.560208\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:56 INFO 139658144298816] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15692.052125930786, \"sum\": 15692.052125930786, \"min\": 15692.052125930786}}, \"EndTime\": 1587687476.354607, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687460.662275}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:56 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.8288670222 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:56 INFO 139658144298816] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=79, train loss <loss>=2.58034677505\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:17:56 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:05 INFO 139658144298816] Epoch[80] Batch[0] avg_epoch_loss=2.643948\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=2.64394807816\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:09 INFO 139658144298816] Epoch[80] Batch[5] avg_epoch_loss=2.549804\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=2.54980353514\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:09 INFO 139658144298816] Epoch[80] Batch [5]#011Speed: 92.57 samples/sec#011loss=2.549804\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:18:12 INFO 139658144298816] Epoch[80] Batch[10] avg_epoch_loss=2.597656\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=2.65507965088\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:12 INFO 139658144298816] Epoch[80] Batch [10]#011Speed: 87.88 samples/sec#011loss=2.655080\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:12 INFO 139658144298816] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16593.913078308105, \"sum\": 16593.913078308105, \"min\": 16593.913078308105}}, \"EndTime\": 1587687492.948914, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687476.354662}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:12 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.7978785028 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:12 INFO 139658144298816] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=80, train loss <loss>=2.59765631502\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:12 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:22 INFO 139658144298816] Epoch[81] Batch[0] avg_epoch_loss=2.524121\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=2.52412104607\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:25 INFO 139658144298816] Epoch[81] Batch[5] avg_epoch_loss=2.566211\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:25 INFO 139658144298816] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=2.56621090571\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:25 INFO 139658144298816] Epoch[81] Batch [5]#011Speed: 93.15 samples/sec#011loss=2.566211\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:29 INFO 139658144298816] Epoch[81] Batch[10] avg_epoch_loss=2.554051\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=2.53945970535\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:29 INFO 139658144298816] Epoch[81] Batch [10]#011Speed: 88.95 samples/sec#011loss=2.539460\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:29 INFO 139658144298816] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16532.23204612732, \"sum\": 16532.23204612732, \"min\": 16532.23204612732}}, \"EndTime\": 1587687509.481477, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687492.948973}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:29 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.7403675252 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:29 INFO 139658144298816] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=81, train loss <loss>=2.55405126918\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:29 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:38 INFO 139658144298816] Epoch[82] Batch[0] avg_epoch_loss=2.479838\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=2.47983837128\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:42 INFO 139658144298816] Epoch[82] Batch[5] avg_epoch_loss=2.554493\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:42 INFO 139658144298816] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=2.55449310939\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:42 INFO 139658144298816] Epoch[82] Batch [5]#011Speed: 92.48 samples/sec#011loss=2.554493\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:45 INFO 139658144298816] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15760.052919387817, \"sum\": 15760.052919387817, \"min\": 15760.052919387817}}, \"EndTime\": 1587687525.241866, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687509.481528}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:45 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.2280892704 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:45 INFO 139658144298816] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=82, train loss <loss>=2.58280551434\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:45 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:54 INFO 139658144298816] Epoch[83] Batch[0] avg_epoch_loss=2.638343\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=2.63834309578\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:58 INFO 139658144298816] Epoch[83] Batch[5] avg_epoch_loss=2.608734\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:58 INFO 139658144298816] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=2.60873381297\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:18:58 INFO 139658144298816] Epoch[83] Batch [5]#011Speed: 92.88 samples/sec#011loss=2.608734\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:01 INFO 139658144298816] Epoch[83] Batch[10] avg_epoch_loss=2.607121\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=2.60518474579\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:01 INFO 139658144298816] Epoch[83] Batch [10]#011Speed: 87.86 samples/sec#011loss=2.605185\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:01 INFO 139658144298816] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16542.91296005249, \"sum\": 16542.91296005249, \"min\": 16542.91296005249}}, \"EndTime\": 1587687541.785108, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687525.241919}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:01 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.7475132396 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:01 INFO 139658144298816] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=83, train loss <loss>=2.60712060061\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:01 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:11 INFO 139658144298816] Epoch[84] Batch[0] avg_epoch_loss=2.743936\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:11 INFO 139658144298816] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=2.74393558502\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:14 INFO 139658144298816] Epoch[84] Batch[5] avg_epoch_loss=2.593046\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=2.59304587046\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:14 INFO 139658144298816] Epoch[84] Batch [5]#011Speed: 92.48 samples/sec#011loss=2.593046\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:18 INFO 139658144298816] Epoch[84] Batch[10] avg_epoch_loss=2.483534\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=2.35211970806\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:18 INFO 139658144298816] Epoch[84] Batch [10]#011Speed: 89.94 samples/sec#011loss=2.352120\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:18 INFO 139658144298816] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16479.023933410645, \"sum\": 16479.023933410645, \"min\": 16479.023933410645}}, \"EndTime\": 1587687558.264474, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687541.785166}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:18 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.3225432404 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:18 INFO 139658144298816] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=84, train loss <loss>=2.48353397846\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:18 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:18 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_d99102be-747b-4e59-80f9-f1e325bdb6c4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 206.56800270080566, \"sum\": 206.56800270080566, \"min\": 206.56800270080566}}, \"EndTime\": 1587687558.471355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687558.264523}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:27 INFO 139658144298816] Epoch[85] Batch[0] avg_epoch_loss=2.624662\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:27 INFO 139658144298816] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=2.62466239929\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:31 INFO 139658144298816] Epoch[85] Batch[5] avg_epoch_loss=2.619885\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:31 INFO 139658144298816] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=2.61988472939\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:31 INFO 139658144298816] Epoch[85] Batch [5]#011Speed: 92.42 samples/sec#011loss=2.619885\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:19:34 INFO 139658144298816] processed a total of 592 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15670.074939727783, \"sum\": 15670.074939727783, \"min\": 15670.074939727783}}, \"EndTime\": 1587687574.141528, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687558.471406}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:34 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=37.778831881 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:34 INFO 139658144298816] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=85, train loss <loss>=2.6363055706\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:34 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:43 INFO 139658144298816] Epoch[86] Batch[0] avg_epoch_loss=2.550296\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:43 INFO 139658144298816] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=2.55029559135\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:47 INFO 139658144298816] Epoch[86] Batch[5] avg_epoch_loss=2.534828\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=2.53482802709\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:47 INFO 139658144298816] Epoch[86] Batch [5]#011Speed: 92.68 samples/sec#011loss=2.534828\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:49 INFO 139658144298816] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15764.552116394043, \"sum\": 15764.552116394043, \"min\": 15764.552116394043}}, \"EndTime\": 1587687589.906376, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687574.141579}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:49 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.0897601641 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:49 INFO 139658144298816] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=86, train loss <loss>=2.53263478279\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:49 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:59 INFO 139658144298816] Epoch[87] Batch[0] avg_epoch_loss=2.507909\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:19:59 INFO 139658144298816] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=2.50790929794\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:02 INFO 139658144298816] Epoch[87] Batch[5] avg_epoch_loss=2.549017\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=2.54901663462\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:02 INFO 139658144298816] Epoch[87] Batch [5]#011Speed: 93.41 samples/sec#011loss=2.549017\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:06 INFO 139658144298816] Epoch[87] Batch[10] avg_epoch_loss=2.575528\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=2.60734057426\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:06 INFO 139658144298816] Epoch[87] Batch [10]#011Speed: 90.67 samples/sec#011loss=2.607341\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:06 INFO 139658144298816] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16406.91089630127, \"sum\": 16406.91089630127, \"min\": 16406.91089630127}}, \"EndTime\": 1587687606.313637, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687589.906426}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:06 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4953469567 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:06 INFO 139658144298816] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=87, train loss <loss>=2.57552751628\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:06 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:15 INFO 139658144298816] Epoch[88] Batch[0] avg_epoch_loss=2.644936\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=2.64493584633\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:19 INFO 139658144298816] Epoch[88] Batch[5] avg_epoch_loss=2.606262\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=2.60626165072\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:19 INFO 139658144298816] Epoch[88] Batch [5]#011Speed: 93.79 samples/sec#011loss=2.606262\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:22 INFO 139658144298816] processed a total of 595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15690.014123916626, \"sum\": 15690.014123916626, \"min\": 15690.014123916626}}, \"EndTime\": 1587687622.003999, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687606.313695}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:22 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=37.9219799843 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:22 INFO 139658144298816] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=88, train loss <loss>=2.61846897602\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:22 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:31 INFO 139658144298816] Epoch[89] Batch[0] avg_epoch_loss=2.579772\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:31 INFO 139658144298816] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=2.57977247238\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:34 INFO 139658144298816] Epoch[89] Batch[5] avg_epoch_loss=2.545053\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=2.54505344232\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:34 INFO 139658144298816] Epoch[89] Batch [5]#011Speed: 93.30 samples/sec#011loss=2.545053\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:38 INFO 139658144298816] Epoch[89] Batch[10] avg_epoch_loss=2.601308\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=2.66881318092\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:38 INFO 139658144298816] Epoch[89] Batch [10]#011Speed: 90.02 samples/sec#011loss=2.668813\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:38 INFO 139658144298816] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16523.189783096313, \"sum\": 16523.189783096313, \"min\": 16523.189783096313}}, \"EndTime\": 1587687638.527563, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687622.004064}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:38 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.8226503034 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:38 INFO 139658144298816] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=89, train loss <loss>=2.60130786896\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:38 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:47 INFO 139658144298816] Epoch[90] Batch[0] avg_epoch_loss=2.526353\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=2.52635264397\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:51 INFO 139658144298816] Epoch[90] Batch[5] avg_epoch_loss=2.554106\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:51 INFO 139658144298816] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=2.55410563946\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:51 INFO 139658144298816] Epoch[90] Batch [5]#011Speed: 92.75 samples/sec#011loss=2.554106\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:54 INFO 139658144298816] Epoch[90] Batch[10] avg_epoch_loss=2.625502\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=2.71117653847\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:54 INFO 139658144298816] Epoch[90] Batch [10]#011Speed: 90.93 samples/sec#011loss=2.711177\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:54 INFO 139658144298816] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16438.297986984253, \"sum\": 16438.297986984253, \"min\": 16438.297986984253}}, \"EndTime\": 1587687654.966115, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687638.527608}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:54 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.602461524 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:54 INFO 139658144298816] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=90, train loss <loss>=2.62550150264\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:20:54 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:21:04 INFO 139658144298816] Epoch[91] Batch[0] avg_epoch_loss=2.647434\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:04 INFO 139658144298816] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=2.64743423462\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:08 INFO 139658144298816] Epoch[91] Batch[5] avg_epoch_loss=2.600381\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=2.60038121541\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:08 INFO 139658144298816] Epoch[91] Batch [5]#011Speed: 92.71 samples/sec#011loss=2.600381\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:11 INFO 139658144298816] Epoch[91] Batch[10] avg_epoch_loss=2.596012\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:11 INFO 139658144298816] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=2.59076886177\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:11 INFO 139658144298816] Epoch[91] Batch [10]#011Speed: 90.76 samples/sec#011loss=2.590769\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:11 INFO 139658144298816] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16650.394916534424, \"sum\": 16650.394916534424, \"min\": 16650.394916534424}}, \"EndTime\": 1587687671.616859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687654.966165}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:11 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.7405783756 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:11 INFO 139658144298816] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:11 INFO 139658144298816] #quality_metric: host=algo-1, epoch=91, train loss <loss>=2.59601196376\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:11 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:21 INFO 139658144298816] Epoch[92] Batch[0] avg_epoch_loss=2.577876\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=2.57787632942\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:24 INFO 139658144298816] Epoch[92] Batch[5] avg_epoch_loss=2.560308\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=2.56030809879\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:24 INFO 139658144298816] Epoch[92] Batch [5]#011Speed: 93.29 samples/sec#011loss=2.560308\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:28 INFO 139658144298816] Epoch[92] Batch[10] avg_epoch_loss=2.565972\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=2.57276921272\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:28 INFO 139658144298816] Epoch[92] Batch [10]#011Speed: 90.75 samples/sec#011loss=2.572769\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:28 INFO 139658144298816] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16444.78487968445, \"sum\": 16444.78487968445, \"min\": 16444.78487968445}}, \"EndTime\": 1587687688.061895, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687671.616905}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:28 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.2287004684 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:28 INFO 139658144298816] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=92, train loss <loss>=2.56597224149\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:28 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:37 INFO 139658144298816] Epoch[93] Batch[0] avg_epoch_loss=2.440964\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=2.44096422195\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:40 INFO 139658144298816] Epoch[93] Batch[5] avg_epoch_loss=2.515951\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=2.51595056057\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:40 INFO 139658144298816] Epoch[93] Batch [5]#011Speed: 93.03 samples/sec#011loss=2.515951\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:43 INFO 139658144298816] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15703.081130981445, \"sum\": 15703.081130981445, \"min\": 15703.081130981445}}, \"EndTime\": 1587687703.76523, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687688.061942}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:43 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.5650811293 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:43 INFO 139658144298816] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:43 INFO 139658144298816] #quality_metric: host=algo-1, epoch=93, train loss <loss>=2.52256946564\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:43 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:53 INFO 139658144298816] Epoch[94] Batch[0] avg_epoch_loss=2.556458\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=2.55645847321\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:56 INFO 139658144298816] Epoch[94] Batch[5] avg_epoch_loss=2.563465\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=2.56346547604\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:21:56 INFO 139658144298816] Epoch[94] Batch [5]#011Speed: 93.19 samples/sec#011loss=2.563465\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:00 INFO 139658144298816] Epoch[94] Batch[10] avg_epoch_loss=2.644731\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:00 INFO 139658144298816] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=2.74224925041\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:00 INFO 139658144298816] Epoch[94] Batch [10]#011Speed: 89.75 samples/sec#011loss=2.742249\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:00 INFO 139658144298816] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16479.70199584961, \"sum\": 16479.70199584961, \"min\": 16479.70199584961}}, \"EndTime\": 1587687720.24529, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687703.765285}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:00 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.0782058096 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:00 INFO 139658144298816] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:00 INFO 139658144298816] #quality_metric: host=algo-1, epoch=94, train loss <loss>=2.64473082803\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:00 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:09 INFO 139658144298816] Epoch[95] Batch[0] avg_epoch_loss=2.598737\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=2.59873723984\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:13 INFO 139658144298816] Epoch[95] Batch[5] avg_epoch_loss=2.577561\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=2.57756086191\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:13 INFO 139658144298816] Epoch[95] Batch [5]#011Speed: 92.48 samples/sec#011loss=2.577561\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:15 INFO 139658144298816] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15754.085063934326, \"sum\": 15754.085063934326, \"min\": 15754.085063934326}}, \"EndTime\": 1587687735.999639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687720.245337}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:15 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.6085879036 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:15 INFO 139658144298816] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=95, train loss <loss>=2.57022719383\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:15 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:25 INFO 139658144298816] Epoch[96] Batch[0] avg_epoch_loss=2.442827\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:25 INFO 139658144298816] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=2.44282746315\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:28 INFO 139658144298816] Epoch[96] Batch[5] avg_epoch_loss=2.503329\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=2.50332883994\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:28 INFO 139658144298816] Epoch[96] Batch [5]#011Speed: 93.15 samples/sec#011loss=2.503329\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:22:32 INFO 139658144298816] Epoch[96] Batch[10] avg_epoch_loss=2.530973\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=2.56414694786\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:32 INFO 139658144298816] Epoch[96] Batch [10]#011Speed: 89.59 samples/sec#011loss=2.564147\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:32 INFO 139658144298816] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16459.93399620056, \"sum\": 16459.93399620056, \"min\": 16459.93399620056}}, \"EndTime\": 1587687752.459868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687735.999689}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:32 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.2466419894 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:32 INFO 139658144298816] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=96, train loss <loss>=2.53097343445\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:32 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:41 INFO 139658144298816] Epoch[97] Batch[0] avg_epoch_loss=2.575252\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=2.57525229454\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:45 INFO 139658144298816] Epoch[97] Batch[5] avg_epoch_loss=2.541632\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=2.54163205624\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:45 INFO 139658144298816] Epoch[97] Batch [5]#011Speed: 92.61 samples/sec#011loss=2.541632\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:48 INFO 139658144298816] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15727.91314125061, \"sum\": 15727.91314125061, \"min\": 15727.91314125061}}, \"EndTime\": 1587687768.188067, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687752.459918}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:48 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4837534092 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:48 INFO 139658144298816] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:48 INFO 139658144298816] #quality_metric: host=algo-1, epoch=97, train loss <loss>=2.55218472481\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:48 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:57 INFO 139658144298816] Epoch[98] Batch[0] avg_epoch_loss=2.525049\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:22:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=2.52504944801\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:01 INFO 139658144298816] Epoch[98] Batch[5] avg_epoch_loss=2.552302\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=2.55230247974\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:01 INFO 139658144298816] Epoch[98] Batch [5]#011Speed: 92.77 samples/sec#011loss=2.552302\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:03 INFO 139658144298816] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15659.740924835205, \"sum\": 15659.740924835205, \"min\": 15659.740924835205}}, \"EndTime\": 1587687783.848127, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687768.188118}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:03 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.144764087 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:03 INFO 139658144298816] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:03 INFO 139658144298816] #quality_metric: host=algo-1, epoch=98, train loss <loss>=2.54694809914\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:03 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:13 INFO 139658144298816] Epoch[99] Batch[0] avg_epoch_loss=2.636261\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=2.63626146317\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:16 INFO 139658144298816] Epoch[99] Batch[5] avg_epoch_loss=2.579990\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:16 INFO 139658144298816] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=2.57999038696\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:16 INFO 139658144298816] Epoch[99] Batch [5]#011Speed: 93.08 samples/sec#011loss=2.579990\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:19 INFO 139658144298816] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15759.055137634277, \"sum\": 15759.055137634277, \"min\": 15759.055137634277}}, \"EndTime\": 1587687799.607567, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687783.848184}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:19 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4056761505 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:19 INFO 139658144298816] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=99, train loss <loss>=2.58050613403\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:19 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:29 INFO 139658144298816] Epoch[100] Batch[0] avg_epoch_loss=2.480162\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=2.48016190529\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:32 INFO 139658144298816] Epoch[100] Batch[5] avg_epoch_loss=2.534705\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=2.53470520178\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:32 INFO 139658144298816] Epoch[100] Batch [5]#011Speed: 93.38 samples/sec#011loss=2.534705\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:35 INFO 139658144298816] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15671.571016311646, \"sum\": 15671.571016311646, \"min\": 15671.571016311646}}, \"EndTime\": 1587687815.279516, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687799.607634}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:35 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.3704102158 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:35 INFO 139658144298816] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:35 INFO 139658144298816] #quality_metric: host=algo-1, epoch=100, train loss <loss>=2.55628831387\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:35 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:44 INFO 139658144298816] Epoch[101] Batch[0] avg_epoch_loss=2.503201\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:44 INFO 139658144298816] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=2.50320148468\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:48 INFO 139658144298816] Epoch[101] Batch[5] avg_epoch_loss=2.495487\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:48 INFO 139658144298816] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=2.49548713366\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:48 INFO 139658144298816] Epoch[101] Batch [5]#011Speed: 94.06 samples/sec#011loss=2.495487\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:51 INFO 139658144298816] Epoch[101] Batch[10] avg_epoch_loss=2.536502\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:51 INFO 139658144298816] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=2.58572039604\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:51 INFO 139658144298816] Epoch[101] Batch [10]#011Speed: 90.58 samples/sec#011loss=2.585720\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:51 INFO 139658144298816] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16430.912017822266, \"sum\": 16430.912017822266, \"min\": 16430.912017822266}}, \"EndTime\": 1587687831.710814, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687815.279584}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:51 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4376483614 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:51 INFO 139658144298816] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:51 INFO 139658144298816] #quality_metric: host=algo-1, epoch=101, train loss <loss>=2.53650225293\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:23:51 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:24:01 INFO 139658144298816] Epoch[102] Batch[0] avg_epoch_loss=2.413398\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=2.41339755058\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:04 INFO 139658144298816] Epoch[102] Batch[5] avg_epoch_loss=2.479268\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:04 INFO 139658144298816] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=2.47926779588\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:04 INFO 139658144298816] Epoch[102] Batch [5]#011Speed: 93.05 samples/sec#011loss=2.479268\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:08 INFO 139658144298816] Epoch[102] Batch[10] avg_epoch_loss=2.472720\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=2.46486339569\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:08 INFO 139658144298816] Epoch[102] Batch [10]#011Speed: 90.85 samples/sec#011loss=2.464863\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:08 INFO 139658144298816] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16496.227025985718, \"sum\": 16496.227025985718, \"min\": 16496.227025985718}}, \"EndTime\": 1587687848.20737, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687831.710874}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:08 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.0695670834 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:08 INFO 139658144298816] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=102, train loss <loss>=2.47272034125\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:08 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:08 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_98ce93e1-8bf3-47b2-a6d9-c77ea4c96317-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 213.623046875, \"sum\": 213.623046875, \"min\": 213.623046875}}, \"EndTime\": 1587687848.421356, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687848.207427}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:17 INFO 139658144298816] Epoch[103] Batch[0] avg_epoch_loss=2.537193\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:17 INFO 139658144298816] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=2.5371928215\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:21 INFO 139658144298816] Epoch[103] Batch[5] avg_epoch_loss=2.548307\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=2.54830650489\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:21 INFO 139658144298816] Epoch[103] Batch [5]#011Speed: 93.29 samples/sec#011loss=2.548307\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:24 INFO 139658144298816] Epoch[103] Batch[10] avg_epoch_loss=2.568630\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=2.59301891327\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:24 INFO 139658144298816] Epoch[103] Batch [10]#011Speed: 90.42 samples/sec#011loss=2.593019\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:24 INFO 139658144298816] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16446.349143981934, \"sum\": 16446.349143981934, \"min\": 16446.349143981934}}, \"EndTime\": 1587687864.867817, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687848.421412}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:24 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.5558916963 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:24 INFO 139658144298816] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=103, train loss <loss>=2.56863032688\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:24 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:34 INFO 139658144298816] Epoch[104] Batch[0] avg_epoch_loss=2.448022\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=2.44802212715\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:37 INFO 139658144298816] Epoch[104] Batch[5] avg_epoch_loss=2.526163\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=2.52616290251\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:37 INFO 139658144298816] Epoch[104] Batch [5]#011Speed: 94.07 samples/sec#011loss=2.526163\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:40 INFO 139658144298816] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15720.61800956726, \"sum\": 15720.61800956726, \"min\": 15720.61800956726}}, \"EndTime\": 1587687880.588764, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687864.867877}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:40 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.6928666558 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:40 INFO 139658144298816] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=104, train loss <loss>=2.51400134563\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:40 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:50 INFO 139658144298816] Epoch[105] Batch[0] avg_epoch_loss=2.533327\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:50 INFO 139658144298816] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=2.53332710266\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:53 INFO 139658144298816] Epoch[105] Batch[5] avg_epoch_loss=2.549641\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=2.54964133104\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:53 INFO 139658144298816] Epoch[105] Batch [5]#011Speed: 93.64 samples/sec#011loss=2.549641\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:56 INFO 139658144298816] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15669.875860214233, \"sum\": 15669.875860214233, \"min\": 15669.875860214233}}, \"EndTime\": 1587687896.259008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687880.588827}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:56 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.3319520944 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:56 INFO 139658144298816] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=105, train loss <loss>=2.5541128397\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:24:56 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:05 INFO 139658144298816] Epoch[106] Batch[0] avg_epoch_loss=2.750798\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=2.75079798698\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:09 INFO 139658144298816] Epoch[106] Batch[5] avg_epoch_loss=2.580843\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=2.58084257444\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:09 INFO 139658144298816] Epoch[106] Batch [5]#011Speed: 92.23 samples/sec#011loss=2.580843\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:11 INFO 139658144298816] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15730.255126953125, \"sum\": 15730.255126953125, \"min\": 15730.255126953125}}, \"EndTime\": 1587687911.989617, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687896.259061}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:11 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.0964266339 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:11 INFO 139658144298816] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:11 INFO 139658144298816] #quality_metric: host=algo-1, epoch=106, train loss <loss>=2.52819542885\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:11 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:21 INFO 139658144298816] Epoch[107] Batch[0] avg_epoch_loss=2.507785\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=2.50778484344\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:24 INFO 139658144298816] Epoch[107] Batch[5] avg_epoch_loss=2.528135\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=2.52813522021\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:24 INFO 139658144298816] Epoch[107] Batch [5]#011Speed: 92.69 samples/sec#011loss=2.528135\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:25:27 INFO 139658144298816] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15772.978067398071, \"sum\": 15772.978067398071, \"min\": 15772.978067398071}}, \"EndTime\": 1587687927.762962, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687911.989673}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:27 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.6735378967 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:27 INFO 139658144298816] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:27 INFO 139658144298816] #quality_metric: host=algo-1, epoch=107, train loss <loss>=2.5459697485\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:27 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:37 INFO 139658144298816] Epoch[108] Batch[0] avg_epoch_loss=2.651438\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=2.65143752098\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:40 INFO 139658144298816] Epoch[108] Batch[5] avg_epoch_loss=2.547608\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=2.54760758082\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:40 INFO 139658144298816] Epoch[108] Batch [5]#011Speed: 92.20 samples/sec#011loss=2.547608\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:43 INFO 139658144298816] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15754.837036132812, \"sum\": 15754.837036132812, \"min\": 15754.837036132812}}, \"EndTime\": 1587687943.518154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687927.763014}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:43 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.3683573373 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:43 INFO 139658144298816] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:43 INFO 139658144298816] #quality_metric: host=algo-1, epoch=108, train loss <loss>=2.53273224831\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:43 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:52 INFO 139658144298816] Epoch[109] Batch[0] avg_epoch_loss=2.538912\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=2.53891205788\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:56 INFO 139658144298816] Epoch[109] Batch[5] avg_epoch_loss=2.542539\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=2.54253880183\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:56 INFO 139658144298816] Epoch[109] Batch [5]#011Speed: 92.52 samples/sec#011loss=2.542539\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:59 INFO 139658144298816] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15720.070838928223, \"sum\": 15720.070838928223, \"min\": 15720.070838928223}}, \"EndTime\": 1587687959.23855, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687943.518206}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:59 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.3303678992 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:59 INFO 139658144298816] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:59 INFO 139658144298816] #quality_metric: host=algo-1, epoch=109, train loss <loss>=2.55693635941\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:25:59 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:08 INFO 139658144298816] Epoch[110] Batch[0] avg_epoch_loss=2.424473\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=2.42447304726\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:12 INFO 139658144298816] Epoch[110] Batch[5] avg_epoch_loss=2.523051\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=2.52305050691\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:12 INFO 139658144298816] Epoch[110] Batch [5]#011Speed: 92.44 samples/sec#011loss=2.523051\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:15 INFO 139658144298816] Epoch[110] Batch[10] avg_epoch_loss=2.506175\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=2.48592371941\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:15 INFO 139658144298816] Epoch[110] Batch [10]#011Speed: 89.46 samples/sec#011loss=2.485924\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:15 INFO 139658144298816] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16531.140089035034, \"sum\": 16531.140089035034, \"min\": 16531.140089035034}}, \"EndTime\": 1587687975.7701, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687959.238615}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:15 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.5010312036 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:15 INFO 139658144298816] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=110, train loss <loss>=2.50617469441\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:15 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:25 INFO 139658144298816] Epoch[111] Batch[0] avg_epoch_loss=2.596489\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:25 INFO 139658144298816] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=2.59648895264\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:28 INFO 139658144298816] Epoch[111] Batch[5] avg_epoch_loss=2.536503\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=2.53650263945\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:28 INFO 139658144298816] Epoch[111] Batch [5]#011Speed: 93.77 samples/sec#011loss=2.536503\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:31 INFO 139658144298816] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15673.396110534668, \"sum\": 15673.396110534668, \"min\": 15673.396110534668}}, \"EndTime\": 1587687991.443782, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687975.770148}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:31 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.5780690437 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:31 INFO 139658144298816] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:31 INFO 139658144298816] #quality_metric: host=algo-1, epoch=111, train loss <loss>=2.55975370407\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:31 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:40 INFO 139658144298816] Epoch[112] Batch[0] avg_epoch_loss=2.588449\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=2.58844852448\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:44 INFO 139658144298816] Epoch[112] Batch[5] avg_epoch_loss=2.564494\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:44 INFO 139658144298816] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=2.56449389458\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:44 INFO 139658144298816] Epoch[112] Batch [5]#011Speed: 92.90 samples/sec#011loss=2.564494\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:47 INFO 139658144298816] Epoch[112] Batch[10] avg_epoch_loss=2.552965\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=2.53913059235\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:47 INFO 139658144298816] Epoch[112] Batch [10]#011Speed: 90.64 samples/sec#011loss=2.539131\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:47 INFO 139658144298816] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16401.302099227905, \"sum\": 16401.302099227905, \"min\": 16401.302099227905}}, \"EndTime\": 1587688007.845464, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587687991.443848}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:47 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.4234352707 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:47 INFO 139658144298816] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=112, train loss <loss>=2.55296512084\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:47 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:26:57 INFO 139658144298816] Epoch[113] Batch[0] avg_epoch_loss=2.514939\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:26:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=2.51493859291\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:00 INFO 139658144298816] Epoch[113] Batch[5] avg_epoch_loss=2.532343\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:00 INFO 139658144298816] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=2.53234306971\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:00 INFO 139658144298816] Epoch[113] Batch [5]#011Speed: 92.78 samples/sec#011loss=2.532343\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:03 INFO 139658144298816] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15694.221019744873, \"sum\": 15694.221019744873, \"min\": 15694.221019744873}}, \"EndTime\": 1587688023.540001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688007.845514}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:03 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.3773537213 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:03 INFO 139658144298816] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:03 INFO 139658144298816] #quality_metric: host=algo-1, epoch=113, train loss <loss>=2.55153055191\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:03 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:13 INFO 139658144298816] Epoch[114] Batch[0] avg_epoch_loss=2.466042\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=2.4660422802\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:16 INFO 139658144298816] Epoch[114] Batch[5] avg_epoch_loss=2.520169\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:16 INFO 139658144298816] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=2.52016909917\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:16 INFO 139658144298816] Epoch[114] Batch [5]#011Speed: 93.60 samples/sec#011loss=2.520169\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:20 INFO 139658144298816] Epoch[114] Batch[10] avg_epoch_loss=2.549942\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=2.58566918373\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:20 INFO 139658144298816] Epoch[114] Batch [10]#011Speed: 90.92 samples/sec#011loss=2.585669\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:20 INFO 139658144298816] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16518.96619796753, \"sum\": 16518.96619796753, \"min\": 16518.96619796753}}, \"EndTime\": 1587688040.059303, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688023.540056}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:20 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.6197988978 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:20 INFO 139658144298816] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=114, train loss <loss>=2.54994186488\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:20 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:29 INFO 139658144298816] Epoch[115] Batch[0] avg_epoch_loss=2.453640\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=2.45363950729\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:32 INFO 139658144298816] Epoch[115] Batch[5] avg_epoch_loss=2.602150\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=2.60214996338\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:32 INFO 139658144298816] Epoch[115] Batch [5]#011Speed: 93.10 samples/sec#011loss=2.602150\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:36 INFO 139658144298816] Epoch[115] Batch[10] avg_epoch_loss=2.552488\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=2.49289264679\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:36 INFO 139658144298816] Epoch[115] Batch [10]#011Speed: 89.70 samples/sec#011loss=2.492893\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:36 INFO 139658144298816] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16424.73316192627, \"sum\": 16424.73316192627, \"min\": 16424.73316192627}}, \"EndTime\": 1587688056.484332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688040.059351}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:36 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.6351785324 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:36 INFO 139658144298816] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=115, train loss <loss>=2.55248754675\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:36 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:45 INFO 139658144298816] Epoch[116] Batch[0] avg_epoch_loss=2.580305\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=2.58030509949\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:49 INFO 139658144298816] Epoch[116] Batch[5] avg_epoch_loss=2.551076\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=2.5510764122\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:49 INFO 139658144298816] Epoch[116] Batch [5]#011Speed: 92.62 samples/sec#011loss=2.551076\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:52 INFO 139658144298816] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15665.212869644165, \"sum\": 15665.212869644165, \"min\": 15665.212869644165}}, \"EndTime\": 1587688072.14983, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688056.484379}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:52 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.9609707443 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:52 INFO 139658144298816] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=116, train loss <loss>=2.56556756496\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:27:52 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:01 INFO 139658144298816] Epoch[117] Batch[0] avg_epoch_loss=2.548157\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=2.54815721512\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:04 INFO 139658144298816] Epoch[117] Batch[5] avg_epoch_loss=2.513884\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:04 INFO 139658144298816] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=2.51388382912\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:04 INFO 139658144298816] Epoch[117] Batch [5]#011Speed: 93.35 samples/sec#011loss=2.513884\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:07 INFO 139658144298816] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15657.780885696411, \"sum\": 15657.780885696411, \"min\": 15657.780885696411}}, \"EndTime\": 1587688087.807973, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688072.14988}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:07 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.3631066605 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:07 INFO 139658144298816] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:07 INFO 139658144298816] #quality_metric: host=algo-1, epoch=117, train loss <loss>=2.50707101822\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:07 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:17 INFO 139658144298816] Epoch[118] Batch[0] avg_epoch_loss=2.552636\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:17 INFO 139658144298816] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=2.55263590813\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:20 INFO 139658144298816] Epoch[118] Batch[5] avg_epoch_loss=2.478709\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=2.47870949904\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:20 INFO 139658144298816] Epoch[118] Batch [5]#011Speed: 93.30 samples/sec#011loss=2.478709\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:23 INFO 139658144298816] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15661.525011062622, \"sum\": 15661.525011062622, \"min\": 15661.525011062622}}, \"EndTime\": 1587688103.469864, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688087.808026}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:23 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.0125643024 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:23 INFO 139658144298816] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:23 INFO 139658144298816] #quality_metric: host=algo-1, epoch=118, train loss <loss>=2.51312150955\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:23 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:28:32 INFO 139658144298816] Epoch[119] Batch[0] avg_epoch_loss=2.534245\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=2.53424501419\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:36 INFO 139658144298816] Epoch[119] Batch[5] avg_epoch_loss=2.490284\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=2.49028408527\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:36 INFO 139658144298816] Epoch[119] Batch [5]#011Speed: 94.61 samples/sec#011loss=2.490284\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:39 INFO 139658144298816] Epoch[119] Batch[10] avg_epoch_loss=2.496406\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:39 INFO 139658144298816] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=2.5037522316\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:39 INFO 139658144298816] Epoch[119] Batch [10]#011Speed: 90.32 samples/sec#011loss=2.503752\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:39 INFO 139658144298816] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16431.133031845093, \"sum\": 16431.133031845093, \"min\": 16431.133031845093}}, \"EndTime\": 1587688119.901374, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688103.469929}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:39 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.8715151752 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:39 INFO 139658144298816] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:39 INFO 139658144298816] #quality_metric: host=algo-1, epoch=119, train loss <loss>=2.49640596997\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:39 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:49 INFO 139658144298816] Epoch[120] Batch[0] avg_epoch_loss=2.607430\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=2.60743021965\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:52 INFO 139658144298816] Epoch[120] Batch[5] avg_epoch_loss=2.564723\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=2.56472281615\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:52 INFO 139658144298816] Epoch[120] Batch [5]#011Speed: 93.84 samples/sec#011loss=2.564723\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:56 INFO 139658144298816] Epoch[120] Batch[10] avg_epoch_loss=2.658693\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=2.77145676613\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:56 INFO 139658144298816] Epoch[120] Batch [10]#011Speed: 90.61 samples/sec#011loss=2.771457\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:56 INFO 139658144298816] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16476.410150527954, \"sum\": 16476.410150527954, \"min\": 16476.410150527954}}, \"EndTime\": 1587688136.378101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688119.901432}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:56 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.9645954293 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:56 INFO 139658144298816] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=120, train loss <loss>=2.65869279341\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:28:56 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:05 INFO 139658144298816] Epoch[121] Batch[0] avg_epoch_loss=2.402480\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=2.40247988701\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:09 INFO 139658144298816] Epoch[121] Batch[5] avg_epoch_loss=2.516971\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=2.51697146893\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:09 INFO 139658144298816] Epoch[121] Batch [5]#011Speed: 94.12 samples/sec#011loss=2.516971\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:12 INFO 139658144298816] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15688.321113586426, \"sum\": 15688.321113586426, \"min\": 15688.321113586426}}, \"EndTime\": 1587688152.066793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688136.37816}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:12 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.7306194898 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:12 INFO 139658144298816] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=121, train loss <loss>=2.53418893814\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:12 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:21 INFO 139658144298816] Epoch[122] Batch[0] avg_epoch_loss=2.518728\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=2.51872849464\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:25 INFO 139658144298816] Epoch[122] Batch[5] avg_epoch_loss=2.541595\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:25 INFO 139658144298816] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=2.54159470399\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:25 INFO 139658144298816] Epoch[122] Batch [5]#011Speed: 93.90 samples/sec#011loss=2.541595\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:28 INFO 139658144298816] Epoch[122] Batch[10] avg_epoch_loss=2.524807\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=2.50466160774\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:28 INFO 139658144298816] Epoch[122] Batch [10]#011Speed: 91.15 samples/sec#011loss=2.504662\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:28 INFO 139658144298816] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16484.144926071167, \"sum\": 16484.144926071167, \"min\": 16484.144926071167}}, \"EndTime\": 1587688168.551321, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688152.066858}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:28 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.6136162003 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:28 INFO 139658144298816] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=122, train loss <loss>=2.52480693297\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:28 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:37 INFO 139658144298816] Epoch[123] Batch[0] avg_epoch_loss=2.572721\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=2.57272076607\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:41 INFO 139658144298816] Epoch[123] Batch[5] avg_epoch_loss=2.528757\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=2.52875729402\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:41 INFO 139658144298816] Epoch[123] Batch [5]#011Speed: 93.71 samples/sec#011loss=2.528757\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:44 INFO 139658144298816] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15680.938005447388, \"sum\": 15680.938005447388, \"min\": 15680.938005447388}}, \"EndTime\": 1587688184.232585, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688168.55138}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:44 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.5178609016 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:44 INFO 139658144298816] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:44 INFO 139658144298816] #quality_metric: host=algo-1, epoch=123, train loss <loss>=2.57769193649\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:44 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:53 INFO 139658144298816] Epoch[124] Batch[0] avg_epoch_loss=2.541194\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=2.5411939621\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:57 INFO 139658144298816] Epoch[124] Batch[5] avg_epoch_loss=2.500002\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=2.50000162919\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:29:57 INFO 139658144298816] Epoch[124] Batch [5]#011Speed: 93.17 samples/sec#011loss=2.500002\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:30:00 INFO 139658144298816] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15788.753986358643, \"sum\": 15788.753986358643, \"min\": 15788.753986358643}}, \"EndTime\": 1587688200.021717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688184.232652}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:00 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.6482709157 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:00 INFO 139658144298816] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:00 INFO 139658144298816] #quality_metric: host=algo-1, epoch=124, train loss <loss>=2.53385546207\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:00 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:09 INFO 139658144298816] Epoch[125] Batch[0] avg_epoch_loss=2.588295\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=2.58829474449\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:12 INFO 139658144298816] Epoch[125] Batch[5] avg_epoch_loss=2.564646\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=2.56464640299\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:12 INFO 139658144298816] Epoch[125] Batch [5]#011Speed: 93.59 samples/sec#011loss=2.564646\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:16 INFO 139658144298816] Epoch[125] Batch[10] avg_epoch_loss=2.535108\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:16 INFO 139658144298816] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=2.49966082573\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:16 INFO 139658144298816] Epoch[125] Batch [10]#011Speed: 90.13 samples/sec#011loss=2.499661\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:16 INFO 139658144298816] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16507.318019866943, \"sum\": 16507.318019866943, \"min\": 16507.318019866943}}, \"EndTime\": 1587688216.529412, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688200.021773}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:16 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.4667265807 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:16 INFO 139658144298816] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:16 INFO 139658144298816] #quality_metric: host=algo-1, epoch=125, train loss <loss>=2.53510750424\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:16 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:26 INFO 139658144298816] Epoch[126] Batch[0] avg_epoch_loss=2.390539\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=2.39053940773\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:29 INFO 139658144298816] Epoch[126] Batch[5] avg_epoch_loss=2.533163\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=2.53316326936\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:29 INFO 139658144298816] Epoch[126] Batch [5]#011Speed: 92.50 samples/sec#011loss=2.533163\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:33 INFO 139658144298816] Epoch[126] Batch[10] avg_epoch_loss=2.505889\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=2.47315964699\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:33 INFO 139658144298816] Epoch[126] Batch [10]#011Speed: 90.19 samples/sec#011loss=2.473160\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:33 INFO 139658144298816] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16636.434078216553, \"sum\": 16636.434078216553, \"min\": 16636.434078216553}}, \"EndTime\": 1587688233.166128, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688216.529459}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:33 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.0542938811 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:33 INFO 139658144298816] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=126, train loss <loss>=2.50588889555\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:33 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:42 INFO 139658144298816] Epoch[127] Batch[0] avg_epoch_loss=2.625399\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:42 INFO 139658144298816] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=2.62539935112\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:46 INFO 139658144298816] Epoch[127] Batch[5] avg_epoch_loss=2.587367\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:46 INFO 139658144298816] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=2.58736689885\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:46 INFO 139658144298816] Epoch[127] Batch [5]#011Speed: 92.72 samples/sec#011loss=2.587367\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:49 INFO 139658144298816] Epoch[127] Batch[10] avg_epoch_loss=2.501759\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=2.39902853966\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:49 INFO 139658144298816] Epoch[127] Batch [10]#011Speed: 89.70 samples/sec#011loss=2.399029\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:49 INFO 139658144298816] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16554.87895011902, \"sum\": 16554.87895011902, \"min\": 16554.87895011902}}, \"EndTime\": 1587688249.721295, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688233.166177}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:49 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.1088421125 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:49 INFO 139658144298816] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=127, train loss <loss>=2.50175855377\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:49 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:59 INFO 139658144298816] Epoch[128] Batch[0] avg_epoch_loss=2.514860\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:30:59 INFO 139658144298816] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=2.5148601532\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:02 INFO 139658144298816] Epoch[128] Batch[5] avg_epoch_loss=2.571760\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=2.5717596213\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:02 INFO 139658144298816] Epoch[128] Batch [5]#011Speed: 92.07 samples/sec#011loss=2.571760\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:05 INFO 139658144298816] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15972.455024719238, \"sum\": 15972.455024719238, \"min\": 15972.455024719238}}, \"EndTime\": 1587688265.694038, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688249.721344}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:05 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.7557535677 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:05 INFO 139658144298816] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=128, train loss <loss>=2.56106903553\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:05 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:15 INFO 139658144298816] Epoch[129] Batch[0] avg_epoch_loss=2.553273\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=2.55327272415\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:18 INFO 139658144298816] Epoch[129] Batch[5] avg_epoch_loss=2.525349\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=2.5253491799\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:18 INFO 139658144298816] Epoch[129] Batch [5]#011Speed: 93.06 samples/sec#011loss=2.525349\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:21 INFO 139658144298816] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15740.83399772644, \"sum\": 15740.83399772644, \"min\": 15740.83399772644}}, \"EndTime\": 1587688281.435181, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688265.69409}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:21 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.5618867579 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:21 INFO 139658144298816] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=129, train loss <loss>=2.54360029697\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:21 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:31:30 INFO 139658144298816] Epoch[130] Batch[0] avg_epoch_loss=2.643299\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:30 INFO 139658144298816] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=2.64329886436\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:34 INFO 139658144298816] Epoch[130] Batch[5] avg_epoch_loss=2.569317\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=2.5693166256\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:34 INFO 139658144298816] Epoch[130] Batch [5]#011Speed: 93.50 samples/sec#011loss=2.569317\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:37 INFO 139658144298816] Epoch[130] Batch[10] avg_epoch_loss=2.605159\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=2.64816961288\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:37 INFO 139658144298816] Epoch[130] Batch [10]#011Speed: 89.94 samples/sec#011loss=2.648170\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:37 INFO 139658144298816] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16537.222862243652, \"sum\": 16537.222862243652, \"min\": 16537.222862243652}}, \"EndTime\": 1587688297.972789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688281.435249}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:37 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4260131745 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:37 INFO 139658144298816] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=130, train loss <loss>=2.60515889254\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:37 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:47 INFO 139658144298816] Epoch[131] Batch[0] avg_epoch_loss=2.494563\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=2.49456310272\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:50 INFO 139658144298816] Epoch[131] Batch[5] avg_epoch_loss=2.511084\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:50 INFO 139658144298816] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=2.51108384132\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:50 INFO 139658144298816] Epoch[131] Batch [5]#011Speed: 94.13 samples/sec#011loss=2.511084\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:53 INFO 139658144298816] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15679.548025131226, \"sum\": 15679.548025131226, \"min\": 15679.548025131226}}, \"EndTime\": 1587688313.652661, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688297.972844}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:53 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.988162854 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:53 INFO 139658144298816] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=131, train loss <loss>=2.5197234869\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:31:53 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:03 INFO 139658144298816] Epoch[132] Batch[0] avg_epoch_loss=2.505186\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:03 INFO 139658144298816] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=2.50518608093\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:06 INFO 139658144298816] Epoch[132] Batch[5] avg_epoch_loss=2.462046\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=2.46204586824\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:06 INFO 139658144298816] Epoch[132] Batch [5]#011Speed: 93.23 samples/sec#011loss=2.462046\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:09 INFO 139658144298816] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15781.119108200073, \"sum\": 15781.119108200073, \"min\": 15781.119108200073}}, \"EndTime\": 1587688329.434159, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688313.652725}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:09 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.9208807368 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:09 INFO 139658144298816] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=132, train loss <loss>=2.47983646393\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:09 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:18 INFO 139658144298816] Epoch[133] Batch[0] avg_epoch_loss=2.617745\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=2.61774468422\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:22 INFO 139658144298816] Epoch[133] Batch[5] avg_epoch_loss=2.532992\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=2.53299156825\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:22 INFO 139658144298816] Epoch[133] Batch [5]#011Speed: 93.47 samples/sec#011loss=2.532992\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:25 INFO 139658144298816] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15677.66785621643, \"sum\": 15677.66785621643, \"min\": 15677.66785621643}}, \"EndTime\": 1587688345.112221, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688329.434226}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:25 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.9929560363 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:25 INFO 139658144298816] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:25 INFO 139658144298816] #quality_metric: host=algo-1, epoch=133, train loss <loss>=2.52099311352\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:25 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:34 INFO 139658144298816] Epoch[134] Batch[0] avg_epoch_loss=2.500183\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=2.50018286705\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:38 INFO 139658144298816] Epoch[134] Batch[5] avg_epoch_loss=2.501037\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=2.50103727976\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:38 INFO 139658144298816] Epoch[134] Batch [5]#011Speed: 93.42 samples/sec#011loss=2.501037\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:41 INFO 139658144298816] Epoch[134] Batch[10] avg_epoch_loss=2.410213\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=2.30122416019\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:41 INFO 139658144298816] Epoch[134] Batch [10]#011Speed: 90.97 samples/sec#011loss=2.301224\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:41 INFO 139658144298816] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16407.33814239502, \"sum\": 16407.33814239502, \"min\": 16407.33814239502}}, \"EndTime\": 1587688361.519938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688345.112286}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:41 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.5552745749 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:41 INFO 139658144298816] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=134, train loss <loss>=2.41021313451\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:41 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:41 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_81220d32-03aa-4d90-bf2e-146749498856-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 207.1068286895752, \"sum\": 207.1068286895752, \"min\": 207.1068286895752}}, \"EndTime\": 1587688361.727394, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688361.519994}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:51 INFO 139658144298816] Epoch[135] Batch[0] avg_epoch_loss=2.370538\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:51 INFO 139658144298816] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=2.37053847313\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:54 INFO 139658144298816] Epoch[135] Batch[5] avg_epoch_loss=2.465252\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=2.46525196234\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:54 INFO 139658144298816] Epoch[135] Batch [5]#011Speed: 92.19 samples/sec#011loss=2.465252\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:57 INFO 139658144298816] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15679.579973220825, \"sum\": 15679.579973220825, \"min\": 15679.579973220825}}, \"EndTime\": 1587688377.407076, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688361.727446}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:57 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.074812521 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:57 INFO 139658144298816] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=135, train loss <loss>=2.52990291119\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:32:57 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:33:06 INFO 139658144298816] Epoch[136] Batch[0] avg_epoch_loss=2.451754\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=2.45175409317\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:10 INFO 139658144298816] Epoch[136] Batch[5] avg_epoch_loss=2.467879\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:10 INFO 139658144298816] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=2.46787873904\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:10 INFO 139658144298816] Epoch[136] Batch [5]#011Speed: 93.00 samples/sec#011loss=2.467879\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:13 INFO 139658144298816] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15766.0231590271, \"sum\": 15766.0231590271, \"min\": 15766.0231590271}}, \"EndTime\": 1587688393.173459, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688377.407129}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:13 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.0859590028 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:13 INFO 139658144298816] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=136, train loss <loss>=2.49871146679\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:13 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:22 INFO 139658144298816] Epoch[137] Batch[0] avg_epoch_loss=2.394663\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=2.39466261864\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:25 INFO 139658144298816] Epoch[137] Batch[5] avg_epoch_loss=2.481704\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:25 INFO 139658144298816] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=2.48170411587\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:25 INFO 139658144298816] Epoch[137] Batch [5]#011Speed: 93.90 samples/sec#011loss=2.481704\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:28 INFO 139658144298816] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15630.50103187561, \"sum\": 15630.50103187561, \"min\": 15630.50103187561}}, \"EndTime\": 1587688408.804348, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688393.173525}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:28 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.7701202307 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:28 INFO 139658144298816] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=137, train loss <loss>=2.47998716831\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:28 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:38 INFO 139658144298816] Epoch[138] Batch[0] avg_epoch_loss=2.404652\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=2.40465164185\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:41 INFO 139658144298816] Epoch[138] Batch[5] avg_epoch_loss=2.458462\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=2.4584621191\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:41 INFO 139658144298816] Epoch[138] Batch [5]#011Speed: 93.75 samples/sec#011loss=2.458462\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:45 INFO 139658144298816] Epoch[138] Batch[10] avg_epoch_loss=2.462408\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=2.46714401245\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:45 INFO 139658144298816] Epoch[138] Batch [10]#011Speed: 89.99 samples/sec#011loss=2.467144\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:45 INFO 139658144298816] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16409.4979763031, \"sum\": 16409.4979763031, \"min\": 16409.4979763031}}, \"EndTime\": 1587688425.214215, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688408.804412}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:45 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.1954402632 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:45 INFO 139658144298816] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=138, train loss <loss>=2.46240843426\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:45 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:54 INFO 139658144298816] Epoch[139] Batch[0] avg_epoch_loss=2.462204\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=2.46220445633\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:58 INFO 139658144298816] Epoch[139] Batch[5] avg_epoch_loss=2.468573\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:58 INFO 139658144298816] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=2.46857293447\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:33:58 INFO 139658144298816] Epoch[139] Batch [5]#011Speed: 91.58 samples/sec#011loss=2.468573\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:01 INFO 139658144298816] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15954.015970230103, \"sum\": 15954.015970230103, \"min\": 15954.015970230103}}, \"EndTime\": 1587688441.168577, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688425.214274}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:01 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.9270206776 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:01 INFO 139658144298816] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=139, train loss <loss>=2.47177197933\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:01 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:10 INFO 139658144298816] Epoch[140] Batch[0] avg_epoch_loss=2.480798\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:10 INFO 139658144298816] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=2.48079848289\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:14 INFO 139658144298816] Epoch[140] Batch[5] avg_epoch_loss=2.545381\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=2.54538126787\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:14 INFO 139658144298816] Epoch[140] Batch [5]#011Speed: 92.94 samples/sec#011loss=2.545381\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:16 INFO 139658144298816] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15746.623039245605, \"sum\": 15746.623039245605, \"min\": 15746.623039245605}}, \"EndTime\": 1587688456.915571, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688441.168642}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:16 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.881321125 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:16 INFO 139658144298816] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:16 INFO 139658144298816] #quality_metric: host=algo-1, epoch=140, train loss <loss>=2.49323296547\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:16 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:26 INFO 139658144298816] Epoch[141] Batch[0] avg_epoch_loss=2.483306\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=2.48330569267\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:29 INFO 139658144298816] Epoch[141] Batch[5] avg_epoch_loss=2.470803\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=2.47080298265\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:29 INFO 139658144298816] Epoch[141] Batch [5]#011Speed: 93.04 samples/sec#011loss=2.470803\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:32 INFO 139658144298816] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15802.632808685303, \"sum\": 15802.632808685303, \"min\": 15802.632808685303}}, \"EndTime\": 1587688472.71858, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688456.915637}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:32 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.2462614155 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:32 INFO 139658144298816] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=141, train loss <loss>=2.44997298717\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:32 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:34:42 INFO 139658144298816] Epoch[142] Batch[0] avg_epoch_loss=2.395097\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:42 INFO 139658144298816] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=2.39509725571\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:45 INFO 139658144298816] Epoch[142] Batch[5] avg_epoch_loss=2.464460\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=2.46445953846\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:45 INFO 139658144298816] Epoch[142] Batch [5]#011Speed: 93.78 samples/sec#011loss=2.464460\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:49 INFO 139658144298816] Epoch[142] Batch[10] avg_epoch_loss=2.530373\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=2.60946855545\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:49 INFO 139658144298816] Epoch[142] Batch [10]#011Speed: 89.30 samples/sec#011loss=2.609469\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:49 INFO 139658144298816] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16468.7180519104, \"sum\": 16468.7180519104, \"min\": 16468.7180519104}}, \"EndTime\": 1587688489.187638, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688472.718631}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:49 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.0757678873 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:49 INFO 139658144298816] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=142, train loss <loss>=2.530372728\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:49 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:58 INFO 139658144298816] Epoch[143] Batch[0] avg_epoch_loss=2.524618\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:34:58 INFO 139658144298816] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=2.52461767197\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:02 INFO 139658144298816] Epoch[143] Batch[5] avg_epoch_loss=2.530036\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=2.53003593286\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:02 INFO 139658144298816] Epoch[143] Batch [5]#011Speed: 93.75 samples/sec#011loss=2.530036\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:05 INFO 139658144298816] Epoch[143] Batch[10] avg_epoch_loss=2.525933\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=2.5210088253\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:05 INFO 139658144298816] Epoch[143] Batch [10]#011Speed: 89.34 samples/sec#011loss=2.521009\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:05 INFO 139658144298816] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16527.217149734497, \"sum\": 16527.217149734497, \"min\": 16527.217149734497}}, \"EndTime\": 1587688505.715181, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688489.187698}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:05 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.538979114 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:05 INFO 139658144298816] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=143, train loss <loss>=2.52593270215\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:05 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:15 INFO 139658144298816] Epoch[144] Batch[0] avg_epoch_loss=2.439808\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=2.43980836868\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:18 INFO 139658144298816] Epoch[144] Batch[5] avg_epoch_loss=2.451702\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=2.45170195897\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:18 INFO 139658144298816] Epoch[144] Batch [5]#011Speed: 94.04 samples/sec#011loss=2.451702\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:21 INFO 139658144298816] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15742.178201675415, \"sum\": 15742.178201675415, \"min\": 15742.178201675415}}, \"EndTime\": 1587688521.457683, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688505.715239}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:21 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.5278224163 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:21 INFO 139658144298816] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=144, train loss <loss>=2.45614027977\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:21 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:31 INFO 139658144298816] Epoch[145] Batch[0] avg_epoch_loss=2.506755\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:31 INFO 139658144298816] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=2.50675535202\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:34 INFO 139658144298816] Epoch[145] Batch[5] avg_epoch_loss=2.540724\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=2.5407235225\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:34 INFO 139658144298816] Epoch[145] Batch [5]#011Speed: 93.22 samples/sec#011loss=2.540724\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:38 INFO 139658144298816] Epoch[145] Batch[10] avg_epoch_loss=2.511368\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=2.47614102364\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:38 INFO 139658144298816] Epoch[145] Batch [10]#011Speed: 89.96 samples/sec#011loss=2.476141\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:38 INFO 139658144298816] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16607.68699645996, \"sum\": 16607.68699645996, \"min\": 16607.68699645996}}, \"EndTime\": 1587688538.06574, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688521.457748}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:38 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.4264230009 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:38 INFO 139658144298816] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=145, train loss <loss>=2.5113678412\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:38 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:47 INFO 139658144298816] Epoch[146] Batch[0] avg_epoch_loss=2.564455\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=2.56445455551\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:50 INFO 139658144298816] Epoch[146] Batch[5] avg_epoch_loss=2.541695\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:50 INFO 139658144298816] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=2.541694959\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:50 INFO 139658144298816] Epoch[146] Batch [5]#011Speed: 92.77 samples/sec#011loss=2.541695\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:53 INFO 139658144298816] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15695.230960845947, \"sum\": 15695.230960845947, \"min\": 15695.230960845947}}, \"EndTime\": 1587688553.761231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688538.065787}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:53 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.2031026015 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:53 INFO 139658144298816] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=146, train loss <loss>=2.52184112072\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:35:53 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:03 INFO 139658144298816] Epoch[147] Batch[0] avg_epoch_loss=2.521829\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:03 INFO 139658144298816] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=2.52182865143\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:06 INFO 139658144298816] Epoch[147] Batch[5] avg_epoch_loss=2.523097\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=2.52309743563\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:06 INFO 139658144298816] Epoch[147] Batch [5]#011Speed: 91.85 samples/sec#011loss=2.523097\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:09 INFO 139658144298816] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15760.534048080444, \"sum\": 15760.534048080444, \"min\": 15760.534048080444}}, \"EndTime\": 1587688569.522122, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688553.761283}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:09 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.9578803619 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:09 INFO 139658144298816] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=147, train loss <loss>=2.49733066559\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:09 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:36:18 INFO 139658144298816] Epoch[148] Batch[0] avg_epoch_loss=2.525678\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=2.52567839622\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:22 INFO 139658144298816] Epoch[148] Batch[5] avg_epoch_loss=2.558522\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=2.55852162838\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:22 INFO 139658144298816] Epoch[148] Batch [5]#011Speed: 92.94 samples/sec#011loss=2.558522\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:25 INFO 139658144298816] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15730.362892150879, \"sum\": 15730.362892150879, \"min\": 15730.362892150879}}, \"EndTime\": 1587688585.252792, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688569.522173}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:25 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.9225604853 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:25 INFO 139658144298816] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:25 INFO 139658144298816] #quality_metric: host=algo-1, epoch=148, train loss <loss>=2.57232396603\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:25 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:34 INFO 139658144298816] Epoch[149] Batch[0] avg_epoch_loss=2.386127\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=2.38612651825\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:38 INFO 139658144298816] Epoch[149] Batch[5] avg_epoch_loss=2.449390\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=2.44938961665\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:38 INFO 139658144298816] Epoch[149] Batch [5]#011Speed: 92.08 samples/sec#011loss=2.449390\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:41 INFO 139658144298816] Epoch[149] Batch[10] avg_epoch_loss=2.423781\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=2.39304990768\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:41 INFO 139658144298816] Epoch[149] Batch [10]#011Speed: 90.85 samples/sec#011loss=2.393050\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:41 INFO 139658144298816] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16497.660875320435, \"sum\": 16497.660875320435, \"min\": 16497.660875320435}}, \"EndTime\": 1587688601.750871, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688585.252854}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:41 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.0356191969 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:41 INFO 139658144298816] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=149, train loss <loss>=2.42378065803\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:41 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:51 INFO 139658144298816] Epoch[150] Batch[0] avg_epoch_loss=2.582967\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:51 INFO 139658144298816] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=2.58296656609\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:54 INFO 139658144298816] Epoch[150] Batch[5] avg_epoch_loss=2.493061\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=2.4930614233\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:54 INFO 139658144298816] Epoch[150] Batch [5]#011Speed: 93.60 samples/sec#011loss=2.493061\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:57 INFO 139658144298816] processed a total of 590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15620.208024978638, \"sum\": 15620.208024978638, \"min\": 15620.208024978638}}, \"EndTime\": 1587688617.371419, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688601.750933}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:57 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=37.7713666823 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:57 INFO 139658144298816] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=150, train loss <loss>=2.56904051304\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:36:57 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:06 INFO 139658144298816] Epoch[151] Batch[0] avg_epoch_loss=2.451552\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=2.4515516758\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:10 INFO 139658144298816] Epoch[151] Batch[5] avg_epoch_loss=2.519087\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:10 INFO 139658144298816] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=2.51908671856\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:10 INFO 139658144298816] Epoch[151] Batch [5]#011Speed: 93.66 samples/sec#011loss=2.519087\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:13 INFO 139658144298816] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15794.25597190857, \"sum\": 15794.25597190857, \"min\": 15794.25597190857}}, \"EndTime\": 1587688633.166053, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688617.371481}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:13 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.0646024408 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:13 INFO 139658144298816] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=151, train loss <loss>=2.51553821564\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:13 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:22 INFO 139658144298816] Epoch[152] Batch[0] avg_epoch_loss=2.534908\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=2.53490829468\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:26 INFO 139658144298816] Epoch[152] Batch[5] avg_epoch_loss=2.515829\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=2.51582856973\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:26 INFO 139658144298816] Epoch[152] Batch [5]#011Speed: 93.63 samples/sec#011loss=2.515829\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:28 INFO 139658144298816] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15821.74801826477, \"sum\": 15821.74801826477, \"min\": 15821.74801826477}}, \"EndTime\": 1587688648.98819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688633.166118}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:28 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.007984013 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:28 INFO 139658144298816] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=152, train loss <loss>=2.50462548733\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:28 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:38 INFO 139658144298816] Epoch[153] Batch[0] avg_epoch_loss=2.384111\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=2.384111166\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:41 INFO 139658144298816] Epoch[153] Batch[5] avg_epoch_loss=2.506672\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=2.50667186578\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:41 INFO 139658144298816] Epoch[153] Batch [5]#011Speed: 93.67 samples/sec#011loss=2.506672\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:44 INFO 139658144298816] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15891.607999801636, \"sum\": 15891.607999801636, \"min\": 15891.607999801636}}, \"EndTime\": 1587688664.880193, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688648.988256}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:44 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.8321033864 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:44 INFO 139658144298816] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:44 INFO 139658144298816] #quality_metric: host=algo-1, epoch=153, train loss <loss>=2.51393492222\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:44 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:37:54 INFO 139658144298816] Epoch[154] Batch[0] avg_epoch_loss=2.527415\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=2.52741456032\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:57 INFO 139658144298816] Epoch[154] Batch[5] avg_epoch_loss=2.480963\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=2.48096323013\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:37:57 INFO 139658144298816] Epoch[154] Batch [5]#011Speed: 93.72 samples/sec#011loss=2.480963\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:00 INFO 139658144298816] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15807.281970977783, \"sum\": 15807.281970977783, \"min\": 15807.281970977783}}, \"EndTime\": 1587688680.687855, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688664.88026}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:00 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.7282986886 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:00 INFO 139658144298816] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:00 INFO 139658144298816] #quality_metric: host=algo-1, epoch=154, train loss <loss>=2.49514935017\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:00 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:10 INFO 139658144298816] Epoch[155] Batch[0] avg_epoch_loss=2.460887\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:10 INFO 139658144298816] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=2.46088695526\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:13 INFO 139658144298816] Epoch[155] Batch[5] avg_epoch_loss=2.540481\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=2.54048065344\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:13 INFO 139658144298816] Epoch[155] Batch [5]#011Speed: 92.40 samples/sec#011loss=2.540481\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:17 INFO 139658144298816] Epoch[155] Batch[10] avg_epoch_loss=2.531228\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:17 INFO 139658144298816] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=2.52012395859\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:17 INFO 139658144298816] Epoch[155] Batch [10]#011Speed: 90.43 samples/sec#011loss=2.520124\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:17 INFO 139658144298816] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16626.19709968567, \"sum\": 16626.19709968567, \"min\": 16626.19709968567}}, \"EndTime\": 1587688697.314414, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688680.687918}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:17 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.0345744586 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:17 INFO 139658144298816] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:17 INFO 139658144298816] #quality_metric: host=algo-1, epoch=155, train loss <loss>=2.53122761033\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:17 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:26 INFO 139658144298816] Epoch[156] Batch[0] avg_epoch_loss=2.517940\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=2.51794028282\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:30 INFO 139658144298816] Epoch[156] Batch[5] avg_epoch_loss=2.538582\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:30 INFO 139658144298816] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=2.53858208656\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:30 INFO 139658144298816] Epoch[156] Batch [5]#011Speed: 93.94 samples/sec#011loss=2.538582\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:33 INFO 139658144298816] Epoch[156] Batch[10] avg_epoch_loss=2.495431\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=2.44364905357\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:33 INFO 139658144298816] Epoch[156] Batch [10]#011Speed: 89.84 samples/sec#011loss=2.443649\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:33 INFO 139658144298816] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16514.32490348816, \"sum\": 16514.32490348816, \"min\": 16514.32490348816}}, \"EndTime\": 1587688713.829072, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688697.314474}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:33 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.1779080586 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:33 INFO 139658144298816] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=156, train loss <loss>=2.49543070793\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:33 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:43 INFO 139658144298816] Epoch[157] Batch[0] avg_epoch_loss=2.386979\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:43 INFO 139658144298816] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=2.38697910309\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:46 INFO 139658144298816] Epoch[157] Batch[5] avg_epoch_loss=2.526724\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:46 INFO 139658144298816] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=2.52672437827\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:46 INFO 139658144298816] Epoch[157] Batch [5]#011Speed: 93.54 samples/sec#011loss=2.526724\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:49 INFO 139658144298816] processed a total of 585 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15718.46318244934, \"sum\": 15718.46318244934, \"min\": 15718.46318244934}}, \"EndTime\": 1587688729.547857, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688713.82913}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:49 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=37.217147451 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:49 INFO 139658144298816] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=157, train loss <loss>=2.49424240589\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:49 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:59 INFO 139658144298816] Epoch[158] Batch[0] avg_epoch_loss=2.457330\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:38:59 INFO 139658144298816] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=2.4573302269\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:02 INFO 139658144298816] Epoch[158] Batch[5] avg_epoch_loss=2.476085\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=2.47608530521\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:02 INFO 139658144298816] Epoch[158] Batch [5]#011Speed: 93.93 samples/sec#011loss=2.476085\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:06 INFO 139658144298816] Epoch[158] Batch[10] avg_epoch_loss=2.546691\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=2.63141880035\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:06 INFO 139658144298816] Epoch[158] Batch [10]#011Speed: 89.79 samples/sec#011loss=2.631419\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:06 INFO 139658144298816] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16622.7068901062, \"sum\": 16622.7068901062, \"min\": 16622.7068901062}}, \"EndTime\": 1587688746.170943, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688729.547925}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:06 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.223244856 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:06 INFO 139658144298816] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=158, train loss <loss>=2.54669143937\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:06 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:15 INFO 139658144298816] Epoch[159] Batch[0] avg_epoch_loss=2.538589\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=2.53858947754\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:19 INFO 139658144298816] Epoch[159] Batch[5] avg_epoch_loss=2.518623\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=2.51862251759\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:19 INFO 139658144298816] Epoch[159] Batch [5]#011Speed: 93.49 samples/sec#011loss=2.518623\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:22 INFO 139658144298816] Epoch[159] Batch[10] avg_epoch_loss=2.484482\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=2.44351263046\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:22 INFO 139658144298816] Epoch[159] Batch [10]#011Speed: 89.99 samples/sec#011loss=2.443513\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:22 INFO 139658144298816] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16576.792001724243, \"sum\": 16576.792001724243, \"min\": 16576.792001724243}}, \"EndTime\": 1587688762.748078, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688746.171005}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:22 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.7541779768 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:22 INFO 139658144298816] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=159, train loss <loss>=2.4844816598\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:22 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:39:32 INFO 139658144298816] Epoch[160] Batch[0] avg_epoch_loss=2.546409\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=2.54640865326\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:35 INFO 139658144298816] Epoch[160] Batch[5] avg_epoch_loss=2.537879\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:35 INFO 139658144298816] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=2.53787899017\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:35 INFO 139658144298816] Epoch[160] Batch [5]#011Speed: 93.72 samples/sec#011loss=2.537879\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:39 INFO 139658144298816] Epoch[160] Batch[10] avg_epoch_loss=2.452561\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:39 INFO 139658144298816] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=2.35017967224\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:39 INFO 139658144298816] Epoch[160] Batch [10]#011Speed: 89.73 samples/sec#011loss=2.350180\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:39 INFO 139658144298816] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16448.127031326294, \"sum\": 16448.127031326294, \"min\": 16448.127031326294}}, \"EndTime\": 1587688779.196522, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688762.748134}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:39 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.33557302 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:39 INFO 139658144298816] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:39 INFO 139658144298816] #quality_metric: host=algo-1, epoch=160, train loss <loss>=2.45256111839\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:39 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:48 INFO 139658144298816] Epoch[161] Batch[0] avg_epoch_loss=2.314328\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:48 INFO 139658144298816] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=2.31432795525\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:52 INFO 139658144298816] Epoch[161] Batch[5] avg_epoch_loss=2.445569\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=2.44556931655\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:52 INFO 139658144298816] Epoch[161] Batch [5]#011Speed: 93.72 samples/sec#011loss=2.445569\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:54 INFO 139658144298816] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15694.087028503418, \"sum\": 15694.087028503418, \"min\": 15694.087028503418}}, \"EndTime\": 1587688794.890941, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688779.196585}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:54 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.1670147502 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:54 INFO 139658144298816] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=161, train loss <loss>=2.44940714836\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:39:54 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:04 INFO 139658144298816] Epoch[162] Batch[0] avg_epoch_loss=2.493780\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:04 INFO 139658144298816] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=2.49377965927\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:07 INFO 139658144298816] Epoch[162] Batch[5] avg_epoch_loss=2.505148\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:07 INFO 139658144298816] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=2.50514833132\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:07 INFO 139658144298816] Epoch[162] Batch [5]#011Speed: 93.01 samples/sec#011loss=2.505148\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:10 INFO 139658144298816] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15727.741003036499, \"sum\": 15727.741003036499, \"min\": 15727.741003036499}}, \"EndTime\": 1587688810.619079, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688794.891006}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:10 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.7847430569 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:10 INFO 139658144298816] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:10 INFO 139658144298816] #quality_metric: host=algo-1, epoch=162, train loss <loss>=2.55488021374\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:10 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:20 INFO 139658144298816] Epoch[163] Batch[0] avg_epoch_loss=2.483819\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=2.48381876945\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:23 INFO 139658144298816] Epoch[163] Batch[5] avg_epoch_loss=2.488537\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:23 INFO 139658144298816] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=2.48853651683\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:23 INFO 139658144298816] Epoch[163] Batch [5]#011Speed: 93.63 samples/sec#011loss=2.488537\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:26 INFO 139658144298816] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15733.505964279175, \"sum\": 15733.505964279175, \"min\": 15733.505964279175}}, \"EndTime\": 1587688826.35296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688810.619143}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:26 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.5968215455 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:26 INFO 139658144298816] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=163, train loss <loss>=2.48886330128\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:26 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:35 INFO 139658144298816] Epoch[164] Batch[0] avg_epoch_loss=2.536164\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:35 INFO 139658144298816] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=2.53616428375\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:39 INFO 139658144298816] Epoch[164] Batch[5] avg_epoch_loss=2.515145\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:39 INFO 139658144298816] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=2.51514490445\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:39 INFO 139658144298816] Epoch[164] Batch [5]#011Speed: 92.72 samples/sec#011loss=2.515145\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:42 INFO 139658144298816] Epoch[164] Batch[10] avg_epoch_loss=2.542959\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:42 INFO 139658144298816] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=2.57633666992\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:42 INFO 139658144298816] Epoch[164] Batch [10]#011Speed: 90.38 samples/sec#011loss=2.576337\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:42 INFO 139658144298816] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16445.828914642334, \"sum\": 16445.828914642334, \"min\": 16445.828914642334}}, \"EndTime\": 1587688842.799124, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688826.353014}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:42 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.8612132333 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:42 INFO 139658144298816] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:42 INFO 139658144298816] #quality_metric: host=algo-1, epoch=164, train loss <loss>=2.5429593433\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:42 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:52 INFO 139658144298816] Epoch[165] Batch[0] avg_epoch_loss=2.466540\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=2.46654009819\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:55 INFO 139658144298816] Epoch[165] Batch[5] avg_epoch_loss=2.517677\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:55 INFO 139658144298816] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=2.5176765124\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:55 INFO 139658144298816] Epoch[165] Batch [5]#011Speed: 94.04 samples/sec#011loss=2.517677\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:40:58 INFO 139658144298816] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15672.73211479187, \"sum\": 15672.73211479187, \"min\": 15672.73211479187}}, \"EndTime\": 1587688858.472186, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688842.799183}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:58 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.9417381542 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:58 INFO 139658144298816] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:58 INFO 139658144298816] #quality_metric: host=algo-1, epoch=165, train loss <loss>=2.4813035965\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:40:58 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:07 INFO 139658144298816] Epoch[166] Batch[0] avg_epoch_loss=2.382201\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:07 INFO 139658144298816] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=2.38220119476\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:11 INFO 139658144298816] Epoch[166] Batch[5] avg_epoch_loss=2.475547\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:11 INFO 139658144298816] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=2.47554739316\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:11 INFO 139658144298816] Epoch[166] Batch [5]#011Speed: 93.33 samples/sec#011loss=2.475547\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:14 INFO 139658144298816] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15771.132946014404, \"sum\": 15771.132946014404, \"min\": 15771.132946014404}}, \"EndTime\": 1587688874.243705, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688858.472253}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:14 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.1363597815 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:14 INFO 139658144298816] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=166, train loss <loss>=2.48091185093\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:14 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:23 INFO 139658144298816] Epoch[167] Batch[0] avg_epoch_loss=2.521372\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:23 INFO 139658144298816] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=2.52137231827\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:27 INFO 139658144298816] Epoch[167] Batch[5] avg_epoch_loss=2.519072\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:27 INFO 139658144298816] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=2.51907165845\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:27 INFO 139658144298816] Epoch[167] Batch [5]#011Speed: 93.76 samples/sec#011loss=2.519072\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:30 INFO 139658144298816] Epoch[167] Batch[10] avg_epoch_loss=2.480715\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:30 INFO 139658144298816] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=2.43468742371\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:30 INFO 139658144298816] Epoch[167] Batch [10]#011Speed: 90.39 samples/sec#011loss=2.434687\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:30 INFO 139658144298816] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16519.11187171936, \"sum\": 16519.11187171936, \"min\": 16519.11187171936}}, \"EndTime\": 1587688890.763207, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688874.24378}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:30 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.740476772 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:30 INFO 139658144298816] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:30 INFO 139658144298816] #quality_metric: host=algo-1, epoch=167, train loss <loss>=2.48071518811\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:30 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:40 INFO 139658144298816] Epoch[168] Batch[0] avg_epoch_loss=2.306069\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=2.30606865883\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:43 INFO 139658144298816] Epoch[168] Batch[5] avg_epoch_loss=2.499942\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:43 INFO 139658144298816] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=2.49994158745\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:43 INFO 139658144298816] Epoch[168] Batch [5]#011Speed: 93.61 samples/sec#011loss=2.499942\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:47 INFO 139658144298816] Epoch[168] Batch[10] avg_epoch_loss=2.441948\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=2.37235572338\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:47 INFO 139658144298816] Epoch[168] Batch [10]#011Speed: 89.47 samples/sec#011loss=2.372356\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:47 INFO 139658144298816] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16477.118015289307, \"sum\": 16477.118015289307, \"min\": 16477.118015289307}}, \"EndTime\": 1587688907.240656, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688890.763266}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:47 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.0843035805 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:47 INFO 139658144298816] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=168, train loss <loss>=2.44194801287\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:47 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:56 INFO 139658144298816] Epoch[169] Batch[0] avg_epoch_loss=2.566279\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:41:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=2.56627893448\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:00 INFO 139658144298816] Epoch[169] Batch[5] avg_epoch_loss=2.483173\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:00 INFO 139658144298816] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=2.48317281405\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:00 INFO 139658144298816] Epoch[169] Batch [5]#011Speed: 93.26 samples/sec#011loss=2.483173\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:03 INFO 139658144298816] Epoch[169] Batch[10] avg_epoch_loss=2.471679\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:03 INFO 139658144298816] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=2.45788578987\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:03 INFO 139658144298816] Epoch[169] Batch [10]#011Speed: 89.26 samples/sec#011loss=2.457886\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:03 INFO 139658144298816] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16621.679067611694, \"sum\": 16621.679067611694, \"min\": 16621.679067611694}}, \"EndTime\": 1587688923.862652, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688907.240714}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:03 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.789887032 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:03 INFO 139658144298816] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:03 INFO 139658144298816] #quality_metric: host=algo-1, epoch=169, train loss <loss>=2.47167871215\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:03 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:13 INFO 139658144298816] Epoch[170] Batch[0] avg_epoch_loss=2.599458\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=2.59945845604\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:16 INFO 139658144298816] Epoch[170] Batch[5] avg_epoch_loss=2.532841\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:16 INFO 139658144298816] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=2.5328407685\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:16 INFO 139658144298816] Epoch[170] Batch [5]#011Speed: 93.92 samples/sec#011loss=2.532841\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:20 INFO 139658144298816] Epoch[170] Batch[10] avg_epoch_loss=2.507916\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=2.47800717354\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:20 INFO 139658144298816] Epoch[170] Batch [10]#011Speed: 89.87 samples/sec#011loss=2.478007\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:20 INFO 139658144298816] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16646.622896194458, \"sum\": 16646.622896194458, \"min\": 16646.622896194458}}, \"EndTime\": 1587688940.509625, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688923.862712}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:20 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.7888454297 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:20 INFO 139658144298816] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=170, train loss <loss>=2.50791640715\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:20 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:42:30 INFO 139658144298816] Epoch[171] Batch[0] avg_epoch_loss=2.242945\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:30 INFO 139658144298816] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=2.24294471741\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:33 INFO 139658144298816] Epoch[171] Batch[5] avg_epoch_loss=2.415070\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=2.41507033507\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:33 INFO 139658144298816] Epoch[171] Batch [5]#011Speed: 93.00 samples/sec#011loss=2.415070\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:37 INFO 139658144298816] Epoch[171] Batch[10] avg_epoch_loss=2.332623\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=2.23368566036\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:37 INFO 139658144298816] Epoch[171] Batch [10]#011Speed: 89.39 samples/sec#011loss=2.233686\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:37 INFO 139658144298816] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16539.485931396484, \"sum\": 16539.485931396484, \"min\": 16539.485931396484}}, \"EndTime\": 1587688957.049437, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688940.509683}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:37 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.9973742434 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:37 INFO 139658144298816] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=171, train loss <loss>=2.33262275566\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:37 INFO 139658144298816] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:37 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/state_84c9ba5b-4755-466c-a415-8cfdebfbe558-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 213.51218223571777, \"sum\": 213.51218223571777, \"min\": 213.51218223571777}}, \"EndTime\": 1587688957.263317, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688957.049499}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:46 INFO 139658144298816] Epoch[172] Batch[0] avg_epoch_loss=2.392244\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:46 INFO 139658144298816] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=2.39224433899\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:50 INFO 139658144298816] Epoch[172] Batch[5] avg_epoch_loss=2.507920\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:50 INFO 139658144298816] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=2.50792002678\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:50 INFO 139658144298816] Epoch[172] Batch [5]#011Speed: 93.93 samples/sec#011loss=2.507920\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:53 INFO 139658144298816] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15821.415185928345, \"sum\": 15821.415185928345, \"min\": 15821.415185928345}}, \"EndTime\": 1587688973.084833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688957.263368}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:53 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.3767752843 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:53 INFO 139658144298816] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=172, train loss <loss>=2.50695307255\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:42:53 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:02 INFO 139658144298816] Epoch[173] Batch[0] avg_epoch_loss=2.520948\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=2.52094817162\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:06 INFO 139658144298816] Epoch[173] Batch[5] avg_epoch_loss=2.533582\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=2.53358185291\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:06 INFO 139658144298816] Epoch[173] Batch [5]#011Speed: 93.95 samples/sec#011loss=2.533582\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:09 INFO 139658144298816] Epoch[173] Batch[10] avg_epoch_loss=2.561676\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=2.59538936615\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:09 INFO 139658144298816] Epoch[173] Batch [10]#011Speed: 90.00 samples/sec#011loss=2.595389\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:09 INFO 139658144298816] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16534.968852996826, \"sum\": 16534.968852996826, \"min\": 16534.968852996826}}, \"EndTime\": 1587688989.620185, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688973.084898}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:09 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.7337967519 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:09 INFO 139658144298816] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=173, train loss <loss>=2.56167617711\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:09 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:19 INFO 139658144298816] Epoch[174] Batch[0] avg_epoch_loss=2.588303\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=2.58830285072\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:22 INFO 139658144298816] Epoch[174] Batch[5] avg_epoch_loss=2.473873\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=2.47387317816\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:22 INFO 139658144298816] Epoch[174] Batch [5]#011Speed: 91.74 samples/sec#011loss=2.473873\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:26 INFO 139658144298816] Epoch[174] Batch[10] avg_epoch_loss=2.436384\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=2.391395998\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:26 INFO 139658144298816] Epoch[174] Batch [10]#011Speed: 89.68 samples/sec#011loss=2.391396\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:26 INFO 139658144298816] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16713.947057724, \"sum\": 16713.947057724, \"min\": 16713.947057724}}, \"EndTime\": 1587689006.334445, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587688989.620234}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:26 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4877694699 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:26 INFO 139658144298816] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=174, train loss <loss>=2.43638355082\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:26 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:35 INFO 139658144298816] Epoch[175] Batch[0] avg_epoch_loss=2.466393\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:35 INFO 139658144298816] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=2.46639251709\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:39 INFO 139658144298816] Epoch[175] Batch[5] avg_epoch_loss=2.427269\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:39 INFO 139658144298816] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=2.42726929983\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:39 INFO 139658144298816] Epoch[175] Batch [5]#011Speed: 93.24 samples/sec#011loss=2.427269\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:42 INFO 139658144298816] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15811.697006225586, \"sum\": 15811.697006225586, \"min\": 15811.697006225586}}, \"EndTime\": 1587689022.146504, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689006.334505}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:42 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.0728534904 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:42 INFO 139658144298816] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:42 INFO 139658144298816] #quality_metric: host=algo-1, epoch=175, train loss <loss>=2.49119956493\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:42 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:43:51 INFO 139658144298816] Epoch[176] Batch[0] avg_epoch_loss=2.506333\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:51 INFO 139658144298816] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=2.50633335114\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:55 INFO 139658144298816] Epoch[176] Batch[5] avg_epoch_loss=2.548813\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:55 INFO 139658144298816] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=2.54881326358\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:55 INFO 139658144298816] Epoch[176] Batch [5]#011Speed: 92.75 samples/sec#011loss=2.548813\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:58 INFO 139658144298816] Epoch[176] Batch[10] avg_epoch_loss=2.550916\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:58 INFO 139658144298816] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=2.55343990326\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:58 INFO 139658144298816] Epoch[176] Batch [10]#011Speed: 89.69 samples/sec#011loss=2.553440\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:58 INFO 139658144298816] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16591.39108657837, \"sum\": 16591.39108657837, \"min\": 16591.39108657837}}, \"EndTime\": 1587689038.738293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689022.14657}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:58 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.0562020322 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:58 INFO 139658144298816] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:58 INFO 139658144298816] #quality_metric: host=algo-1, epoch=176, train loss <loss>=2.55091628161\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:43:58 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:08 INFO 139658144298816] Epoch[177] Batch[0] avg_epoch_loss=2.477816\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=2.47781586647\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:11 INFO 139658144298816] Epoch[177] Batch[5] avg_epoch_loss=2.591142\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:11 INFO 139658144298816] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=2.59114221732\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:11 INFO 139658144298816] Epoch[177] Batch [5]#011Speed: 93.07 samples/sec#011loss=2.591142\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:14 INFO 139658144298816] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15751.006841659546, \"sum\": 15751.006841659546, \"min\": 15751.006841659546}}, \"EndTime\": 1587689054.489636, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689038.738351}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:14 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.1241816419 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:14 INFO 139658144298816] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=177, train loss <loss>=2.558319664\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:14 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:24 INFO 139658144298816] Epoch[178] Batch[0] avg_epoch_loss=2.568156\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=2.56815624237\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:27 INFO 139658144298816] Epoch[178] Batch[5] avg_epoch_loss=2.522241\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:27 INFO 139658144298816] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=2.52224055926\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:27 INFO 139658144298816] Epoch[178] Batch [5]#011Speed: 93.45 samples/sec#011loss=2.522241\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:30 INFO 139658144298816] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16164.20602798462, \"sum\": 16164.20602798462, \"min\": 16164.20602798462}}, \"EndTime\": 1587689070.654216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689054.489701}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:30 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4078309227 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:30 INFO 139658144298816] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:30 INFO 139658144298816] #quality_metric: host=algo-1, epoch=178, train loss <loss>=2.53149778843\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:30 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:40 INFO 139658144298816] Epoch[179] Batch[0] avg_epoch_loss=2.452637\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=2.45263671875\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:43 INFO 139658144298816] Epoch[179] Batch[5] avg_epoch_loss=2.510567\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:43 INFO 139658144298816] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=2.51056746642\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:43 INFO 139658144298816] Epoch[179] Batch [5]#011Speed: 93.97 samples/sec#011loss=2.510567\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:47 INFO 139658144298816] Epoch[179] Batch[10] avg_epoch_loss=2.461938\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=2.4035826683\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:47 INFO 139658144298816] Epoch[179] Batch [10]#011Speed: 89.54 samples/sec#011loss=2.403583\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:47 INFO 139658144298816] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16663.217067718506, \"sum\": 16663.217067718506, \"min\": 16663.217067718506}}, \"EndTime\": 1587689087.317809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689070.654281}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:47 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.9478484348 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:47 INFO 139658144298816] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:47 INFO 139658144298816] #quality_metric: host=algo-1, epoch=179, train loss <loss>=2.46193801273\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:47 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:56 INFO 139658144298816] Epoch[180] Batch[0] avg_epoch_loss=2.507216\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:44:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=2.50721597672\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:00 INFO 139658144298816] Epoch[180] Batch[5] avg_epoch_loss=2.474842\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:00 INFO 139658144298816] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=2.47484163443\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:00 INFO 139658144298816] Epoch[180] Batch [5]#011Speed: 93.62 samples/sec#011loss=2.474842\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:03 INFO 139658144298816] Epoch[180] Batch[10] avg_epoch_loss=2.456871\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:03 INFO 139658144298816] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=2.43530640602\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:03 INFO 139658144298816] Epoch[180] Batch [10]#011Speed: 89.64 samples/sec#011loss=2.435306\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:03 INFO 139658144298816] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16557.28793144226, \"sum\": 16557.28793144226, \"min\": 16557.28793144226}}, \"EndTime\": 1587689103.875444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689087.317872}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:03 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.4653953558 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:03 INFO 139658144298816] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:03 INFO 139658144298816] #quality_metric: host=algo-1, epoch=180, train loss <loss>=2.45687107606\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:03 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:13 INFO 139658144298816] Epoch[181] Batch[0] avg_epoch_loss=2.576632\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=2.57663249969\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:16 INFO 139658144298816] Epoch[181] Batch[5] avg_epoch_loss=2.485362\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:16 INFO 139658144298816] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=2.48536213239\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:16 INFO 139658144298816] Epoch[181] Batch [5]#011Speed: 93.01 samples/sec#011loss=2.485362\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:45:20 INFO 139658144298816] Epoch[181] Batch[10] avg_epoch_loss=2.498512\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=2.51429171562\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:20 INFO 139658144298816] Epoch[181] Batch [10]#011Speed: 89.44 samples/sec#011loss=2.514292\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:20 INFO 139658144298816] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16405.088186264038, \"sum\": 16405.088186264038, \"min\": 16405.088186264038}}, \"EndTime\": 1587689120.280791, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689103.87549}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:20 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.1949611871 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:20 INFO 139658144298816] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=181, train loss <loss>=2.49851194295\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:20 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:29 INFO 139658144298816] Epoch[182] Batch[0] avg_epoch_loss=2.557871\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=2.55787086487\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:33 INFO 139658144298816] Epoch[182] Batch[5] avg_epoch_loss=2.513834\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=2.51383356253\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:33 INFO 139658144298816] Epoch[182] Batch [5]#011Speed: 92.89 samples/sec#011loss=2.513834\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:36 INFO 139658144298816] Epoch[182] Batch[10] avg_epoch_loss=2.488383\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=2.45784182549\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:36 INFO 139658144298816] Epoch[182] Batch [10]#011Speed: 90.11 samples/sec#011loss=2.457842\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:36 INFO 139658144298816] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16358.166933059692, \"sum\": 16358.166933059692, \"min\": 16358.166933059692}}, \"EndTime\": 1587689136.63927, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689120.280845}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:36 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.4077573463 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:36 INFO 139658144298816] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:36 INFO 139658144298816] #quality_metric: host=algo-1, epoch=182, train loss <loss>=2.48838277297\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:36 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:45 INFO 139658144298816] Epoch[183] Batch[0] avg_epoch_loss=2.481730\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=2.48172974586\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:49 INFO 139658144298816] Epoch[183] Batch[5] avg_epoch_loss=2.490069\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=2.49006919066\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:49 INFO 139658144298816] Epoch[183] Batch [5]#011Speed: 93.06 samples/sec#011loss=2.490069\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:52 INFO 139658144298816] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15557.61694908142, \"sum\": 15557.61694908142, \"min\": 15557.61694908142}}, \"EndTime\": 1587689152.197204, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689136.639321}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:52 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.0086558482 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:52 INFO 139658144298816] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=183, train loss <loss>=2.4722982645\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:45:52 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:01 INFO 139658144298816] Epoch[184] Batch[0] avg_epoch_loss=2.499466\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=2.49946570396\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:04 INFO 139658144298816] Epoch[184] Batch[5] avg_epoch_loss=2.455010\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:04 INFO 139658144298816] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=2.45500961939\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:04 INFO 139658144298816] Epoch[184] Batch [5]#011Speed: 92.75 samples/sec#011loss=2.455010\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:07 INFO 139658144298816] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15568.85313987732, \"sum\": 15568.85313987732, \"min\": 15568.85313987732}}, \"EndTime\": 1587689167.766386, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689152.197254}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:07 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.465210683 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:07 INFO 139658144298816] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:07 INFO 139658144298816] #quality_metric: host=algo-1, epoch=184, train loss <loss>=2.45620594025\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:07 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:17 INFO 139658144298816] Epoch[185] Batch[0] avg_epoch_loss=2.634643\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:17 INFO 139658144298816] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=2.63464260101\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:21 INFO 139658144298816] Epoch[185] Batch[5] avg_epoch_loss=2.532609\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=2.53260906537\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:21 INFO 139658144298816] Epoch[185] Batch [5]#011Speed: 89.96 samples/sec#011loss=2.532609\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:24 INFO 139658144298816] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16444.2241191864, \"sum\": 16444.2241191864, \"min\": 16444.2241191864}}, \"EndTime\": 1587689184.210916, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689167.766438}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:24 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.3111469206 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:24 INFO 139658144298816] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=185, train loss <loss>=2.50062720776\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:24 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:34 INFO 139658144298816] Epoch[186] Batch[0] avg_epoch_loss=2.556267\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:34 INFO 139658144298816] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=2.55626654625\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:37 INFO 139658144298816] Epoch[186] Batch[5] avg_epoch_loss=2.487121\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=2.48712126414\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:37 INFO 139658144298816] Epoch[186] Batch [5]#011Speed: 92.98 samples/sec#011loss=2.487121\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:40 INFO 139658144298816] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16251.9850730896, \"sum\": 16251.9850730896, \"min\": 16251.9850730896}}, \"EndTime\": 1587689200.46321, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689184.210968}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:40 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.5181749395 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:40 INFO 139658144298816] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:40 INFO 139658144298816] #quality_metric: host=algo-1, epoch=186, train loss <loss>=2.47436156273\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:40 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:46:49 INFO 139658144298816] Epoch[187] Batch[0] avg_epoch_loss=2.446572\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=2.44657182693\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:53 INFO 139658144298816] Epoch[187] Batch[5] avg_epoch_loss=2.476439\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=2.47643923759\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:53 INFO 139658144298816] Epoch[187] Batch [5]#011Speed: 92.32 samples/sec#011loss=2.476439\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:56 INFO 139658144298816] Epoch[187] Batch[10] avg_epoch_loss=2.386323\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=2.27818276882\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:56 INFO 139658144298816] Epoch[187] Batch [10]#011Speed: 90.37 samples/sec#011loss=2.278183\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:56 INFO 139658144298816] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16415.29083251953, \"sum\": 16415.29083251953, \"min\": 16415.29083251953}}, \"EndTime\": 1587689216.878839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689200.463268}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:56 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.2315205605 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:56 INFO 139658144298816] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:56 INFO 139658144298816] #quality_metric: host=algo-1, epoch=187, train loss <loss>=2.38632266088\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:46:56 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:06 INFO 139658144298816] Epoch[188] Batch[0] avg_epoch_loss=2.457890\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=2.45788955688\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:09 INFO 139658144298816] Epoch[188] Batch[5] avg_epoch_loss=2.491528\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:09 INFO 139658144298816] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=2.4915283521\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:09 INFO 139658144298816] Epoch[188] Batch [5]#011Speed: 92.33 samples/sec#011loss=2.491528\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:13 INFO 139658144298816] Epoch[188] Batch[10] avg_epoch_loss=2.505753\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=2.52282152176\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:13 INFO 139658144298816] Epoch[188] Batch [10]#011Speed: 90.06 samples/sec#011loss=2.522822\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:13 INFO 139658144298816] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16502.168893814087, \"sum\": 16502.168893814087, \"min\": 16502.168893814087}}, \"EndTime\": 1587689233.381359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689216.878894}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:13 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.0551637779 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:13 INFO 139658144298816] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:13 INFO 139658144298816] #quality_metric: host=algo-1, epoch=188, train loss <loss>=2.50575252013\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:13 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:22 INFO 139658144298816] Epoch[189] Batch[0] avg_epoch_loss=2.441675\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=2.44167518616\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:26 INFO 139658144298816] Epoch[189] Batch[5] avg_epoch_loss=2.504969\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=2.5049687624\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:26 INFO 139658144298816] Epoch[189] Batch [5]#011Speed: 92.48 samples/sec#011loss=2.504969\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:29 INFO 139658144298816] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15754.672050476074, \"sum\": 15754.672050476074, \"min\": 15754.672050476074}}, \"EndTime\": 1587689249.136321, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689233.381407}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:29 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.2741689324 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:29 INFO 139658144298816] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=189, train loss <loss>=2.52180228233\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:29 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:38 INFO 139658144298816] Epoch[190] Batch[0] avg_epoch_loss=2.557965\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=2.55796527863\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:41 INFO 139658144298816] Epoch[190] Batch[5] avg_epoch_loss=2.506052\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=2.50605217616\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:41 INFO 139658144298816] Epoch[190] Batch [5]#011Speed: 92.80 samples/sec#011loss=2.506052\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:44 INFO 139658144298816] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15722.369909286499, \"sum\": 15722.369909286499, \"min\": 15722.369909286499}}, \"EndTime\": 1587689264.859063, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689249.136374}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:44 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.1796146428 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:44 INFO 139658144298816] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:44 INFO 139658144298816] #quality_metric: host=algo-1, epoch=190, train loss <loss>=2.47872102261\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:44 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:54 INFO 139658144298816] Epoch[191] Batch[0] avg_epoch_loss=2.332492\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=2.33249187469\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:57 INFO 139658144298816] Epoch[191] Batch[5] avg_epoch_loss=2.467428\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:57 INFO 139658144298816] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=2.46742848555\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:47:57 INFO 139658144298816] Epoch[191] Batch [5]#011Speed: 93.80 samples/sec#011loss=2.467428\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:01 INFO 139658144298816] Epoch[191] Batch[10] avg_epoch_loss=2.472119\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=2.47774734497\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:01 INFO 139658144298816] Epoch[191] Batch [10]#011Speed: 90.57 samples/sec#011loss=2.477747\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:01 INFO 139658144298816] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16441.927194595337, \"sum\": 16441.927194595337, \"min\": 16441.927194595337}}, \"EndTime\": 1587689281.301365, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689264.859126}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:01 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4720478396 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:01 INFO 139658144298816] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=191, train loss <loss>=2.4721188762\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:01 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:10 INFO 139658144298816] Epoch[192] Batch[0] avg_epoch_loss=2.527534\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:10 INFO 139658144298816] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=2.52753448486\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:14 INFO 139658144298816] Epoch[192] Batch[5] avg_epoch_loss=2.447362\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=2.44736242294\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:14 INFO 139658144298816] Epoch[192] Batch [5]#011Speed: 93.42 samples/sec#011loss=2.447362\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:17 INFO 139658144298816] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15705.198049545288, \"sum\": 15705.198049545288, \"min\": 15705.198049545288}}, \"EndTime\": 1587689297.006895, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689281.301426}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:17 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.7955468561 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:17 INFO 139658144298816] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:17 INFO 139658144298816] #quality_metric: host=algo-1, epoch=192, train loss <loss>=2.44001626968\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:17 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:48:26 INFO 139658144298816] Epoch[193] Batch[0] avg_epoch_loss=2.384459\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:26 INFO 139658144298816] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=2.38445949554\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:29 INFO 139658144298816] Epoch[193] Batch[5] avg_epoch_loss=2.471065\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:29 INFO 139658144298816] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=2.47106472651\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:29 INFO 139658144298816] Epoch[193] Batch [5]#011Speed: 92.75 samples/sec#011loss=2.471065\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:33 INFO 139658144298816] Epoch[193] Batch[10] avg_epoch_loss=2.415948\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=2.34980788231\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:33 INFO 139658144298816] Epoch[193] Batch [10]#011Speed: 90.03 samples/sec#011loss=2.349808\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:33 INFO 139658144298816] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16454.603910446167, \"sum\": 16454.603910446167, \"min\": 16454.603910446167}}, \"EndTime\": 1587689313.461851, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689297.006947}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:33 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.3808815588 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:33 INFO 139658144298816] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=193, train loss <loss>=2.41594797915\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:33 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:42 INFO 139658144298816] Epoch[194] Batch[0] avg_epoch_loss=2.480067\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:42 INFO 139658144298816] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=2.48006749153\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:46 INFO 139658144298816] Epoch[194] Batch[5] avg_epoch_loss=2.525706\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:46 INFO 139658144298816] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=2.52570553621\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:46 INFO 139658144298816] Epoch[194] Batch [5]#011Speed: 93.40 samples/sec#011loss=2.525706\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:49 INFO 139658144298816] Epoch[194] Batch[10] avg_epoch_loss=2.475051\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=2.41426610947\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:49 INFO 139658144298816] Epoch[194] Batch [10]#011Speed: 89.29 samples/sec#011loss=2.414266\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:49 INFO 139658144298816] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16464.823961257935, \"sum\": 16464.823961257935, \"min\": 16464.823961257935}}, \"EndTime\": 1587689329.926992, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689313.461905}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:49 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.4171558557 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:49 INFO 139658144298816] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=194, train loss <loss>=2.47505125132\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:49 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:59 INFO 139658144298816] Epoch[195] Batch[0] avg_epoch_loss=2.446154\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:48:59 INFO 139658144298816] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=2.44615387917\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:02 INFO 139658144298816] Epoch[195] Batch[5] avg_epoch_loss=2.476455\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=2.47645513217\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:02 INFO 139658144298816] Epoch[195] Batch [5]#011Speed: 93.59 samples/sec#011loss=2.476455\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:06 INFO 139658144298816] Epoch[195] Batch[10] avg_epoch_loss=2.474695\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=2.47258367538\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:06 INFO 139658144298816] Epoch[195] Batch [10]#011Speed: 89.92 samples/sec#011loss=2.472584\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:06 INFO 139658144298816] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16535.89415550232, \"sum\": 16535.89415550232, \"min\": 16535.89415550232}}, \"EndTime\": 1587689346.463203, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689329.927051}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:06 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.4572356245 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:06 INFO 139658144298816] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:06 INFO 139658144298816] #quality_metric: host=algo-1, epoch=195, train loss <loss>=2.47469537908\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:06 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:15 INFO 139658144298816] Epoch[196] Batch[0] avg_epoch_loss=2.478847\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:15 INFO 139658144298816] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=2.47884726524\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:19 INFO 139658144298816] Epoch[196] Batch[5] avg_epoch_loss=2.467720\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:19 INFO 139658144298816] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=2.46772023042\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:19 INFO 139658144298816] Epoch[196] Batch [5]#011Speed: 94.18 samples/sec#011loss=2.467720\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:22 INFO 139658144298816] Epoch[196] Batch[10] avg_epoch_loss=2.490621\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=2.51810178757\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:22 INFO 139658144298816] Epoch[196] Batch [10]#011Speed: 90.53 samples/sec#011loss=2.518102\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:22 INFO 139658144298816] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16398.588180541992, \"sum\": 16398.588180541992, \"min\": 16398.588180541992}}, \"EndTime\": 1587689362.86211, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689346.46326}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:22 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.3934243964 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:22 INFO 139658144298816] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:22 INFO 139658144298816] #quality_metric: host=algo-1, epoch=196, train loss <loss>=2.49062093821\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:22 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:32 INFO 139658144298816] Epoch[197] Batch[0] avg_epoch_loss=2.510152\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:32 INFO 139658144298816] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=2.5101518631\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:35 INFO 139658144298816] Epoch[197] Batch[5] avg_epoch_loss=2.465772\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:35 INFO 139658144298816] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=2.46577163537\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:35 INFO 139658144298816] Epoch[197] Batch [5]#011Speed: 93.64 samples/sec#011loss=2.465772\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:39 INFO 139658144298816] Epoch[197] Batch[10] avg_epoch_loss=2.420668\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:39 INFO 139658144298816] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=2.36654338837\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:39 INFO 139658144298816] Epoch[197] Batch [10]#011Speed: 90.80 samples/sec#011loss=2.366543\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:39 INFO 139658144298816] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16424.721002578735, \"sum\": 16424.721002578735, \"min\": 16424.721002578735}}, \"EndTime\": 1587689379.287173, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689362.862169}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:39 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.2698630969 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:39 INFO 139658144298816] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:39 INFO 139658144298816] #quality_metric: host=algo-1, epoch=197, train loss <loss>=2.42066788673\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:39 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:49:48 INFO 139658144298816] Epoch[198] Batch[0] avg_epoch_loss=2.468083\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:48 INFO 139658144298816] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=2.46808338165\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:52 INFO 139658144298816] Epoch[198] Batch[5] avg_epoch_loss=2.445148\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:52 INFO 139658144298816] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=2.4451482296\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:52 INFO 139658144298816] Epoch[198] Batch [5]#011Speed: 94.08 samples/sec#011loss=2.445148\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:55 INFO 139658144298816] Epoch[198] Batch[10] avg_epoch_loss=2.420891\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:55 INFO 139658144298816] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=2.39178142548\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:55 INFO 139658144298816] Epoch[198] Batch [10]#011Speed: 89.69 samples/sec#011loss=2.391781\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:55 INFO 139658144298816] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16471.524953842163, \"sum\": 16471.524953842163, \"min\": 16471.524953842163}}, \"EndTime\": 1587689395.759026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689379.287232}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:55 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=41.4045717234 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:55 INFO 139658144298816] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:55 INFO 139658144298816] #quality_metric: host=algo-1, epoch=198, train loss <loss>=2.42089059136\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:49:55 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:05 INFO 139658144298816] Epoch[199] Batch[0] avg_epoch_loss=2.506581\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=2.50658130646\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:08 INFO 139658144298816] Epoch[199] Batch[5] avg_epoch_loss=2.496157\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=2.49615720908\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:08 INFO 139658144298816] Epoch[199] Batch [5]#011Speed: 93.14 samples/sec#011loss=2.496157\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:12 INFO 139658144298816] Epoch[199] Batch[10] avg_epoch_loss=2.524609\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=2.55875015259\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:12 INFO 139658144298816] Epoch[199] Batch [10]#011Speed: 89.67 samples/sec#011loss=2.558750\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:12 INFO 139658144298816] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16598.329067230225, \"sum\": 16598.329067230225, \"min\": 16598.329067230225}}, \"EndTime\": 1587689412.35768, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689395.759084}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:12 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=38.6783776756 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:12 INFO 139658144298816] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:12 INFO 139658144298816] #quality_metric: host=algo-1, epoch=199, train loss <loss>=2.52460854704\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:12 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:21 INFO 139658144298816] Epoch[200] Batch[0] avg_epoch_loss=2.457596\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=2.45759606361\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:25 INFO 139658144298816] Epoch[200] Batch[5] avg_epoch_loss=2.444590\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:25 INFO 139658144298816] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=2.4445904096\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:25 INFO 139658144298816] Epoch[200] Batch [5]#011Speed: 93.67 samples/sec#011loss=2.444590\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:28 INFO 139658144298816] Epoch[200] Batch[10] avg_epoch_loss=2.443313\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=2.44178004265\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:28 INFO 139658144298816] Epoch[200] Batch [10]#011Speed: 89.98 samples/sec#011loss=2.441780\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:28 INFO 139658144298816] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16536.48591041565, \"sum\": 16536.48591041565, \"min\": 16536.48591041565}}, \"EndTime\": 1587689428.8945, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689412.357742}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:28 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.2743688852 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:28 INFO 139658144298816] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:28 INFO 139658144298816] #quality_metric: host=algo-1, epoch=200, train loss <loss>=2.44331297007\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:28 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:38 INFO 139658144298816] Epoch[201] Batch[0] avg_epoch_loss=2.402083\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:38 INFO 139658144298816] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=2.40208339691\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:41 INFO 139658144298816] Epoch[201] Batch[5] avg_epoch_loss=2.459290\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:41 INFO 139658144298816] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=2.45929046472\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:41 INFO 139658144298816] Epoch[201] Batch [5]#011Speed: 93.29 samples/sec#011loss=2.459290\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:45 INFO 139658144298816] Epoch[201] Batch[10] avg_epoch_loss=2.452549\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=2.44446029663\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:45 INFO 139658144298816] Epoch[201] Batch [10]#011Speed: 90.87 samples/sec#011loss=2.444460\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:45 INFO 139658144298816] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16439.61811065674, \"sum\": 16439.61811065674, \"min\": 16439.61811065674}}, \"EndTime\": 1587689445.334461, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689428.894559}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:45 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.1126310362 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:45 INFO 139658144298816] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:45 INFO 139658144298816] #quality_metric: host=algo-1, epoch=201, train loss <loss>=2.45254947922\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:45 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:54 INFO 139658144298816] Epoch[202] Batch[0] avg_epoch_loss=2.395606\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:54 INFO 139658144298816] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=2.39560580254\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:58 INFO 139658144298816] Epoch[202] Batch[5] avg_epoch_loss=2.496598\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:58 INFO 139658144298816] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=2.49659816424\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:50:58 INFO 139658144298816] Epoch[202] Batch [5]#011Speed: 93.15 samples/sec#011loss=2.496598\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:01 INFO 139658144298816] Epoch[202] Batch[10] avg_epoch_loss=2.427142\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=2.34379453659\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:01 INFO 139658144298816] Epoch[202] Batch [10]#011Speed: 89.60 samples/sec#011loss=2.343795\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:01 INFO 139658144298816] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16458.999156951904, \"sum\": 16458.999156951904, \"min\": 16458.999156951904}}, \"EndTime\": 1587689461.793796, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689445.334519}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:01 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.0387171961 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:01 INFO 139658144298816] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:01 INFO 139658144298816] #quality_metric: host=algo-1, epoch=202, train loss <loss>=2.42714196985\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:01 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:51:11 INFO 139658144298816] Epoch[203] Batch[0] avg_epoch_loss=2.531775\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:11 INFO 139658144298816] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=2.53177452087\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:14 INFO 139658144298816] Epoch[203] Batch[5] avg_epoch_loss=2.485362\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=2.48536169529\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:14 INFO 139658144298816] Epoch[203] Batch [5]#011Speed: 93.18 samples/sec#011loss=2.485362\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:18 INFO 139658144298816] Epoch[203] Batch[10] avg_epoch_loss=2.444990\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=2.39654436111\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:18 INFO 139658144298816] Epoch[203] Batch [10]#011Speed: 89.47 samples/sec#011loss=2.396544\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:18 INFO 139658144298816] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16474.951028823853, \"sum\": 16474.951028823853, \"min\": 16474.951028823853}}, \"EndTime\": 1587689478.269004, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689461.793843}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:18 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.3322644382 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:18 INFO 139658144298816] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=203, train loss <loss>=2.44499017976\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:18 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:27 INFO 139658144298816] Epoch[204] Batch[0] avg_epoch_loss=2.587127\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:27 INFO 139658144298816] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=2.58712720871\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:31 INFO 139658144298816] Epoch[204] Batch[5] avg_epoch_loss=2.475091\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:31 INFO 139658144298816] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=2.47509133816\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:31 INFO 139658144298816] Epoch[204] Batch [5]#011Speed: 92.58 samples/sec#011loss=2.475091\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:33 INFO 139658144298816] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15672.067880630493, \"sum\": 15672.067880630493, \"min\": 15672.067880630493}}, \"EndTime\": 1587689493.941406, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689478.26905}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:33 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.1987040173 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:33 INFO 139658144298816] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=204, train loss <loss>=2.46256210804\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:33 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:43 INFO 139658144298816] Epoch[205] Batch[0] avg_epoch_loss=2.531311\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:43 INFO 139658144298816] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=2.53131055832\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:46 INFO 139658144298816] Epoch[205] Batch[5] avg_epoch_loss=2.380864\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:46 INFO 139658144298816] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=2.38086370627\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:46 INFO 139658144298816] Epoch[205] Batch [5]#011Speed: 92.24 samples/sec#011loss=2.380864\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:49 INFO 139658144298816] processed a total of 589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15692.193984985352, \"sum\": 15692.193984985352, \"min\": 15692.193984985352}}, \"EndTime\": 1587689509.633932, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689493.941458}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:49 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=37.5343655764 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:49 INFO 139658144298816] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:49 INFO 139658144298816] #quality_metric: host=algo-1, epoch=205, train loss <loss>=2.38833353519\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:49 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:59 INFO 139658144298816] Epoch[206] Batch[0] avg_epoch_loss=2.639365\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:51:59 INFO 139658144298816] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=2.63936543465\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:02 INFO 139658144298816] Epoch[206] Batch[5] avg_epoch_loss=2.501342\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=2.50134237607\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:02 INFO 139658144298816] Epoch[206] Batch [5]#011Speed: 93.68 samples/sec#011loss=2.501342\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:05 INFO 139658144298816] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15688.693046569824, \"sum\": 15688.693046569824, \"min\": 15688.693046569824}}, \"EndTime\": 1587689525.322997, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689509.633996}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:05 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.709892073 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:05 INFO 139658144298816] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=206, train loss <loss>=2.4372834444\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:05 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:14 INFO 139658144298816] Epoch[207] Batch[0] avg_epoch_loss=2.510242\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:14 INFO 139658144298816] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=2.51024222374\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:18 INFO 139658144298816] Epoch[207] Batch[5] avg_epoch_loss=2.456106\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=2.45610582829\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:18 INFO 139658144298816] Epoch[207] Batch [5]#011Speed: 93.13 samples/sec#011loss=2.456106\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:20 INFO 139658144298816] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15623.186111450195, \"sum\": 15623.186111450195, \"min\": 15623.186111450195}}, \"EndTime\": 1587689540.946556, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689525.32306}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:20 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=40.1964271517 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:20 INFO 139658144298816] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:20 INFO 139658144298816] #quality_metric: host=algo-1, epoch=207, train loss <loss>=2.45811200142\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:20 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:30 INFO 139658144298816] Epoch[208] Batch[0] avg_epoch_loss=2.470693\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:30 INFO 139658144298816] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=2.47069311142\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:33 INFO 139658144298816] Epoch[208] Batch[5] avg_epoch_loss=2.447215\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:33 INFO 139658144298816] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=2.44721543789\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:33 INFO 139658144298816] Epoch[208] Batch [5]#011Speed: 93.31 samples/sec#011loss=2.447215\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:37 INFO 139658144298816] Epoch[208] Batch[10] avg_epoch_loss=2.465717\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=2.48791809082\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:37 INFO 139658144298816] Epoch[208] Batch [10]#011Speed: 90.61 samples/sec#011loss=2.487918\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:37 INFO 139658144298816] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 16464.5779132843, \"sum\": 16464.5779132843, \"min\": 16464.5779132843}}, \"EndTime\": 1587689557.411525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689540.94662}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:37 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.1748072144 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:37 INFO 139658144298816] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:37 INFO 139658144298816] #quality_metric: host=algo-1, epoch=208, train loss <loss>=2.46571664377\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:37 INFO 139658144298816] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/24/2020 00:52:46 INFO 139658144298816] Epoch[209] Batch[0] avg_epoch_loss=2.592492\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:46 INFO 139658144298816] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=2.59249162674\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:50 INFO 139658144298816] Epoch[209] Batch[5] avg_epoch_loss=2.581632\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:50 INFO 139658144298816] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=2.58163154125\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:50 INFO 139658144298816] Epoch[209] Batch [5]#011Speed: 94.05 samples/sec#011loss=2.581632\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:53 INFO 139658144298816] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15639.203071594238, \"sum\": 15639.203071594238, \"min\": 15639.203071594238}}, \"EndTime\": 1587689573.051054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689557.411584}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:53 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.8994940573 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:53 INFO 139658144298816] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:53 INFO 139658144298816] #quality_metric: host=algo-1, epoch=209, train loss <loss>=2.5354164362\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:52:53 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:02 INFO 139658144298816] Epoch[210] Batch[0] avg_epoch_loss=2.496808\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:02 INFO 139658144298816] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=2.49680805206\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:05 INFO 139658144298816] Epoch[210] Batch[5] avg_epoch_loss=2.501020\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:05 INFO 139658144298816] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=2.50102043152\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:05 INFO 139658144298816] Epoch[210] Batch [5]#011Speed: 92.09 samples/sec#011loss=2.501020\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:08 INFO 139658144298816] processed a total of 580 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15668.65587234497, \"sum\": 15668.65587234497, \"min\": 15668.65587234497}}, \"EndTime\": 1587689588.720075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689573.051118}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:08 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=37.0164036614 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:08 INFO 139658144298816] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:08 INFO 139658144298816] #quality_metric: host=algo-1, epoch=210, train loss <loss>=2.41009155512\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:08 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:18 INFO 139658144298816] Epoch[211] Batch[0] avg_epoch_loss=2.421039\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:18 INFO 139658144298816] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=2.42103886604\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:21 INFO 139658144298816] Epoch[211] Batch[5] avg_epoch_loss=2.474232\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:21 INFO 139658144298816] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=2.47423247496\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:21 INFO 139658144298816] Epoch[211] Batch [5]#011Speed: 93.00 samples/sec#011loss=2.474232\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15648.282051086426, \"sum\": 15648.282051086426, \"min\": 15648.282051086426}}, \"EndTime\": 1587689604.368671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689588.720126}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] #throughput_metric: host=algo-1, train throughput=39.7485312578 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] #quality_metric: host=algo-1, epoch=211, train loss <loss>=2.51503665447\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] Loading parameters from best epoch (171)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 96.43411636352539, \"sum\": 96.43411636352539, \"min\": 96.43411636352539}}, \"EndTime\": 1587689604.465541, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689604.368738}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] stopping training now\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] Final loss: 2.33262275566 (occurred at epoch 171)\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] #quality_metric: host=algo-1, train final_loss <loss>=2.33262275566\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 WARNING 139658144298816] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 WARNING 139658144298816] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:24 INFO 139658144298816] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 27788.04111480713, \"sum\": 27788.04111480713, \"min\": 27788.04111480713}}, \"EndTime\": 1587689632.254182, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689604.46561}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:53 INFO 139658144298816] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 28761.320114135742, \"sum\": 28761.320114135742, \"min\": 28761.320114135742}}, \"EndTime\": 1587689633.227418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689632.256136}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:53 INFO 139658144298816] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:53 INFO 139658144298816] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 122.94411659240723, \"sum\": 122.94411659240723, \"min\": 122.94411659240723}}, \"EndTime\": 1587689633.350452, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689633.227466}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:53 INFO 139658144298816] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:53:53 INFO 139658144298816] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03504753112792969, \"sum\": 0.03504753112792969, \"min\": 0.03504753112792969}}, \"EndTime\": 1587689633.351189, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689633.350496}\n",
      "\u001b[0m\n",
      "\n",
      "2020-04-24 00:54:04 Uploading - Uploading generated training model\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 7033.81609916687, \"sum\": 7033.81609916687, \"min\": 7033.81609916687}}, \"EndTime\": 1587689640.38497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689633.351228}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, RMSE): 38.5073387267\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, mean_absolute_QuantileLoss): 14924.480514382241\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, mean_wQuantileLoss): 0.12398837346832467\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, wQuantileLoss[0.1]): 0.07272935889800582\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, wQuantileLoss[0.2]): 0.11397812384846819\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, wQuantileLoss[0.3]): 0.14257666847282735\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, wQuantileLoss[0.4]): 0.15844429778267383\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, wQuantileLoss[0.5]): 0.16323274924077297\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, wQuantileLoss[0.6]): 0.1559654281539379\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, wQuantileLoss[0.7]): 0.13744616715000585\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, wQuantileLoss[0.8]): 0.10660856332624039\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #test_score (algo-1, wQuantileLoss[0.9]): 0.0649140043419897\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.123988373468\u001b[0m\n",
      "\u001b[34m[04/24/2020 00:54:00 INFO 139658144298816] #quality_metric: host=algo-1, test RMSE <loss>=38.5073387267\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 3485870.540857315, \"sum\": 3485870.540857315, \"min\": 3485870.540857315}, \"setuptime\": {\"count\": 1, \"max\": 7.262945175170898, \"sum\": 7.262945175170898, \"min\": 7.262945175170898}}, \"EndTime\": 1587689640.646677, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1587689640.385038}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-04-24 00:54:16 Completed - Training job completed\n",
      "Training seconds: 3538\n",
      "Billable seconds: 3538\n"
     ]
    }
   ],
   "source": [
    "# This step takes around 35 minutes to train the model with m4.xlarge instance\n",
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job name: deepar-biketrain-with-dynamic-feat-2020-04-23-23-53-26-466\n"
     ]
    }
   ],
   "source": [
    "print ('job name: {0}'.format(job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# Create an endpoint for real-time predictions\n",
    "endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    deployment_image=image_name,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('endpoint name: {0}'.format(endpoint_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to terminate the end point after completing the demo\n",
    "# Otherwise, you account will accumulate hourly charges\n",
    "\n",
    "# you can delete from sagemaker management console or through command line or throught code\n",
    "\n",
    "#sagemaker_session.delete_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
